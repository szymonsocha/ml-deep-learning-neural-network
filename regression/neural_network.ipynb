{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Neural networks"
      ],
      "metadata": {
        "id": "vrWXVfWDhbqE"
      },
      "id": "vrWXVfWDhbqE"
    },
    {
      "cell_type": "code",
      "source": [
        "from random import shuffle\n",
        "from random import randint\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from operator import itemgetter\n",
        "import time\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import gc"
      ],
      "metadata": {
        "id": "5_IYG3zfnwpW"
      },
      "id": "5_IYG3zfnwpW",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load previously prepared data"
      ],
      "metadata": {
        "id": "k51k44_GhfKa"
      },
      "id": "k51k44_GhfKa"
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data/laptop_train.csv')"
      ],
      "metadata": {
        "id": "EGRkLq8CYixB"
      },
      "id": "EGRkLq8CYixB",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3DLT6O5UrrGC",
        "outputId": "5c2ff0d5-310d-4513-85dc-64101c9ed7f9"
      },
      "id": "3DLT6O5UrrGC",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   company  product  typename  inches  cpu  ram(GB)  gpu  opsys  weight(kg)  \\\n",
              "0        4      239         3    15.6   49        6   53      5        2.30   \n",
              "1       10      291         1    15.6   58        8   75      5        2.50   \n",
              "2        4      576         4    13.3   81        8   61      5        1.20   \n",
              "3        2      602         4    13.3   38        8   46      5        1.20   \n",
              "4        4      239         3    15.6   47        4   24      2        2.25   \n",
              "\n",
              "   resolution  screentype  touchscreen  cpu(GHz)  memory_1_storage_gb  \\\n",
              "0           0           2            0       2.4               1000.0   \n",
              "1           3           0            0       2.5                256.0   \n",
              "2           3           2            0       1.8                256.0   \n",
              "3           3           0            0       0.9                512.0   \n",
              "4           0           2            0       2.0               1000.0   \n",
              "\n",
              "   memory_1_type  memory_2_storage_gb  memory_2_type  log_price  \n",
              "0              1                  0.0              3   6.129050  \n",
              "1              3                  0.0              3   6.720220  \n",
              "2              3                  0.0              3   7.364547  \n",
              "3              3                  0.0              3   6.591674  \n",
              "4              1                  0.0              3   6.143370  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e77be06a-1b72-4487-845b-9254340376f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>company</th>\n",
              "      <th>product</th>\n",
              "      <th>typename</th>\n",
              "      <th>inches</th>\n",
              "      <th>cpu</th>\n",
              "      <th>ram(GB)</th>\n",
              "      <th>gpu</th>\n",
              "      <th>opsys</th>\n",
              "      <th>weight(kg)</th>\n",
              "      <th>resolution</th>\n",
              "      <th>screentype</th>\n",
              "      <th>touchscreen</th>\n",
              "      <th>cpu(GHz)</th>\n",
              "      <th>memory_1_storage_gb</th>\n",
              "      <th>memory_1_type</th>\n",
              "      <th>memory_2_storage_gb</th>\n",
              "      <th>memory_2_type</th>\n",
              "      <th>log_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>239</td>\n",
              "      <td>3</td>\n",
              "      <td>15.6</td>\n",
              "      <td>49</td>\n",
              "      <td>6</td>\n",
              "      <td>53</td>\n",
              "      <td>5</td>\n",
              "      <td>2.30</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>6.129050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>291</td>\n",
              "      <td>1</td>\n",
              "      <td>15.6</td>\n",
              "      <td>58</td>\n",
              "      <td>8</td>\n",
              "      <td>75</td>\n",
              "      <td>5</td>\n",
              "      <td>2.50</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>256.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>6.720220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>576</td>\n",
              "      <td>4</td>\n",
              "      <td>13.3</td>\n",
              "      <td>81</td>\n",
              "      <td>8</td>\n",
              "      <td>61</td>\n",
              "      <td>5</td>\n",
              "      <td>1.20</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>256.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>7.364547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>602</td>\n",
              "      <td>4</td>\n",
              "      <td>13.3</td>\n",
              "      <td>38</td>\n",
              "      <td>8</td>\n",
              "      <td>46</td>\n",
              "      <td>5</td>\n",
              "      <td>1.20</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>512.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>6.591674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>239</td>\n",
              "      <td>3</td>\n",
              "      <td>15.6</td>\n",
              "      <td>47</td>\n",
              "      <td>4</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>2.25</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>6.143370</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e77be06a-1b72-4487-845b-9254340376f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e77be06a-1b72-4487-845b-9254340376f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e77be06a-1b72-4487-845b-9254340376f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyT9LOyTnyqw",
        "outputId": "673fa161-d013-43c5-bdd5-77f440e93ef8"
      },
      "id": "JyT9LOyTnyqw",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['company', 'product', 'typename', 'inches', 'cpu', 'ram(GB)', 'gpu',\n",
              "       'opsys', 'weight(kg)', 'resolution', 'screentype', 'touchscreen',\n",
              "       'cpu(GHz)', 'memory_1_storage_gb', 'memory_1_type',\n",
              "       'memory_2_storage_gb', 'memory_2_type', 'log_price'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xhUWGSuwNAl",
        "outputId": "bfeffd2f-2002-4411-dc92-1d9ab1b9deaa"
      },
      "id": "4xhUWGSuwNAl",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1132 entries, 0 to 1131\n",
            "Data columns (total 18 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   company              1132 non-null   int64  \n",
            " 1   product              1132 non-null   int64  \n",
            " 2   typename             1132 non-null   int64  \n",
            " 3   inches               1132 non-null   float64\n",
            " 4   cpu                  1132 non-null   int64  \n",
            " 5   ram(GB)              1132 non-null   int64  \n",
            " 6   gpu                  1132 non-null   int64  \n",
            " 7   opsys                1132 non-null   int64  \n",
            " 8   weight(kg)           1132 non-null   float64\n",
            " 9   resolution           1132 non-null   int64  \n",
            " 10  screentype           1132 non-null   int64  \n",
            " 11  touchscreen          1132 non-null   int64  \n",
            " 12  cpu(GHz)             1132 non-null   float64\n",
            " 13  memory_1_storage_gb  1132 non-null   float64\n",
            " 14  memory_1_type        1132 non-null   int64  \n",
            " 15  memory_2_storage_gb  1132 non-null   float64\n",
            " 16  memory_2_type        1132 non-null   int64  \n",
            " 17  log_price            1132 non-null   float64\n",
            "dtypes: float64(6), int64(12)\n",
            "memory usage: 159.3 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target = \"log_price\"\n",
        "numericFeatures = [\"inches\", \"ram(GB)\", \"weight(kg)\", \"cpu(GHz)\", \"memory_1_storage_gb\", \"memory_2_storage_gb\"]\n",
        "catFeatures = [\"company\", \"product\", \"typename\", \"cpu\", \"gpu\", \"opsys\", \"resolution\", \"screentype\", \"touchscreen\", \"memory_1_type\", \"memory_2_type\"]"
      ],
      "metadata": {
        "id": "vLmN6jgKpWt9"
      },
      "id": "vLmN6jgKpWt9",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# en = LabelEncoder()\n",
        "# for cols in catFeatures:\n",
        "#     df[cols] = en.fit_transform(df[cols])\n",
        "# print('Dataframe encoded by Label encoding dimension : ', df.shape)"
      ],
      "metadata": {
        "id": "9D8vU2S8rtxx"
      },
      "id": "9D8vU2S8rtxx",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One hot encoding\n",
        "#dummLev = pd.get_dummies(df[catFeatures], drop_first=True)\n",
        "\n",
        "# Połączenie zmiennych numerycznych, kategorycznych w postaci on hot encoding oraz targetu\n",
        "#df = pd.concat([df[numericFeatures], dummLev, df[[target]]], axis=1)\n",
        "\n",
        "#df[numericFeatures] = df[numericFeatures].apply(lambda x: (x-x.mean())/x.std())"
      ],
      "metadata": {
        "id": "SM_iuwpF8gd0"
      },
      "id": "SM_iuwpF8gd0",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df[numericFeatures] = df[numericFeatures].apply(lambda x: (x-x.mean())/x.std())"
      ],
      "metadata": {
        "id": "RljeNkOl8jsJ"
      },
      "id": "RljeNkOl8jsJ",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = df.columns.tolist()\n",
        "features.remove(target)"
      ],
      "metadata": {
        "id": "u3CYi66C8m1v"
      },
      "id": "u3CYi66C8m1v",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "XKCs3p_786wm",
        "outputId": "f4732485-e812-4663-e687-4ffd8b13425d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "id": "XKCs3p_786wm",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      company  product  typename  inches  cpu  ram(GB)  gpu  opsys  \\\n",
              "0           4      239         3    15.6   49        6   53      5   \n",
              "1          10      291         1    15.6   58        8   75      5   \n",
              "2           4      576         4    13.3   81        8   61      5   \n",
              "3           2      602         4    13.3   38        8   46      5   \n",
              "4           4      239         3    15.6   47        4   24      2   \n",
              "...       ...      ...       ...     ...  ...      ...  ...    ...   \n",
              "1127        7      111         3    14.0   52        4   47      5   \n",
              "1128        0       77         3    15.6   57        8   86      5   \n",
              "1129        7       27         3    15.6   73        8   53      5   \n",
              "1130        7      324         3    15.6   10        6   29      5   \n",
              "1131       10      456         3    15.6   57        8   53      5   \n",
              "\n",
              "      weight(kg)  resolution  screentype  touchscreen  cpu(GHz)  \\\n",
              "0           2.30           0           2            0       2.4   \n",
              "1           2.50           3           0            0       2.5   \n",
              "2           1.20           3           2            0       1.8   \n",
              "3           1.20           3           0            0       0.9   \n",
              "4           2.25           0           2            0       2.0   \n",
              "...          ...         ...         ...          ...       ...   \n",
              "1127        1.54           3           2            0       2.3   \n",
              "1128        2.40           3           2            0       2.5   \n",
              "1129        2.04           0           2            0       2.7   \n",
              "1130        2.04           3           2            0       2.9   \n",
              "1131        2.30           3           0            0       2.5   \n",
              "\n",
              "      memory_1_storage_gb  memory_1_type  memory_2_storage_gb  memory_2_type  \\\n",
              "0                  1000.0              1                  0.0              3   \n",
              "1                   256.0              3                  0.0              3   \n",
              "2                   256.0              3                  0.0              3   \n",
              "3                   512.0              3                  0.0              3   \n",
              "4                  1000.0              1                  0.0              3   \n",
              "...                   ...            ...                  ...            ...   \n",
              "1127                500.0              1                  0.0              3   \n",
              "1128                256.0              3               1000.0              0   \n",
              "1129               2000.0              1                  0.0              3   \n",
              "1130               1000.0              2                  0.0              3   \n",
              "1131               1000.0              1                  0.0              3   \n",
              "\n",
              "      log_price  \n",
              "0      6.129050  \n",
              "1      6.720220  \n",
              "2      7.364547  \n",
              "3      6.591674  \n",
              "4      6.143370  \n",
              "...         ...  \n",
              "1127   6.907755  \n",
              "1128   6.683361  \n",
              "1129   6.444131  \n",
              "1130   6.309900  \n",
              "1131   6.746013  \n",
              "\n",
              "[1132 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cda219c6-a9a5-4301-a46f-18525d855db0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>company</th>\n",
              "      <th>product</th>\n",
              "      <th>typename</th>\n",
              "      <th>inches</th>\n",
              "      <th>cpu</th>\n",
              "      <th>ram(GB)</th>\n",
              "      <th>gpu</th>\n",
              "      <th>opsys</th>\n",
              "      <th>weight(kg)</th>\n",
              "      <th>resolution</th>\n",
              "      <th>screentype</th>\n",
              "      <th>touchscreen</th>\n",
              "      <th>cpu(GHz)</th>\n",
              "      <th>memory_1_storage_gb</th>\n",
              "      <th>memory_1_type</th>\n",
              "      <th>memory_2_storage_gb</th>\n",
              "      <th>memory_2_type</th>\n",
              "      <th>log_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>239</td>\n",
              "      <td>3</td>\n",
              "      <td>15.6</td>\n",
              "      <td>49</td>\n",
              "      <td>6</td>\n",
              "      <td>53</td>\n",
              "      <td>5</td>\n",
              "      <td>2.30</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>6.129050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>291</td>\n",
              "      <td>1</td>\n",
              "      <td>15.6</td>\n",
              "      <td>58</td>\n",
              "      <td>8</td>\n",
              "      <td>75</td>\n",
              "      <td>5</td>\n",
              "      <td>2.50</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>256.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>6.720220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>576</td>\n",
              "      <td>4</td>\n",
              "      <td>13.3</td>\n",
              "      <td>81</td>\n",
              "      <td>8</td>\n",
              "      <td>61</td>\n",
              "      <td>5</td>\n",
              "      <td>1.20</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>256.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>7.364547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>602</td>\n",
              "      <td>4</td>\n",
              "      <td>13.3</td>\n",
              "      <td>38</td>\n",
              "      <td>8</td>\n",
              "      <td>46</td>\n",
              "      <td>5</td>\n",
              "      <td>1.20</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>512.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>6.591674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>239</td>\n",
              "      <td>3</td>\n",
              "      <td>15.6</td>\n",
              "      <td>47</td>\n",
              "      <td>4</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>2.25</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>6.143370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1127</th>\n",
              "      <td>7</td>\n",
              "      <td>111</td>\n",
              "      <td>3</td>\n",
              "      <td>14.0</td>\n",
              "      <td>52</td>\n",
              "      <td>4</td>\n",
              "      <td>47</td>\n",
              "      <td>5</td>\n",
              "      <td>1.54</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>500.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>6.907755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1128</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>3</td>\n",
              "      <td>15.6</td>\n",
              "      <td>57</td>\n",
              "      <td>8</td>\n",
              "      <td>86</td>\n",
              "      <td>5</td>\n",
              "      <td>2.40</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>256.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.683361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1129</th>\n",
              "      <td>7</td>\n",
              "      <td>27</td>\n",
              "      <td>3</td>\n",
              "      <td>15.6</td>\n",
              "      <td>73</td>\n",
              "      <td>8</td>\n",
              "      <td>53</td>\n",
              "      <td>5</td>\n",
              "      <td>2.04</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2.7</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>6.444131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1130</th>\n",
              "      <td>7</td>\n",
              "      <td>324</td>\n",
              "      <td>3</td>\n",
              "      <td>15.6</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>29</td>\n",
              "      <td>5</td>\n",
              "      <td>2.04</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2.9</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>6.309900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1131</th>\n",
              "      <td>10</td>\n",
              "      <td>456</td>\n",
              "      <td>3</td>\n",
              "      <td>15.6</td>\n",
              "      <td>57</td>\n",
              "      <td>8</td>\n",
              "      <td>53</td>\n",
              "      <td>5</td>\n",
              "      <td>2.30</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>6.746013</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1132 rows × 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cda219c6-a9a5-4301-a46f-18525d855db0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cda219c6-a9a5-4301-a46f-18525d855db0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cda219c6-a9a5-4301-a46f-18525d855db0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#X=df.drop('log_price', axis = 1).values\n",
        "#y=df['log_price'].values"
      ],
      "metadata": {
        "id": "s9wD6jtgwwfC"
      },
      "id": "s9wD6jtgwwfC",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural network"
      ],
      "metadata": {
        "id": "vM_bgNF6fRmN"
      },
      "id": "vM_bgNF6fRmN"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import pickle as pk\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "JkyhweRaRMkR"
      },
      "id": "JkyhweRaRMkR",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.drop('log_price', axis=1)\n",
        "y = df['log_price']"
      ],
      "metadata": {
        "id": "9GlYXAeuQz6H"
      },
      "id": "9GlYXAeuQz6H",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio = 0.70\n",
        "validation_ratio = 0.15\n",
        "test_ratio = 0.15\n",
        "\n",
        "# Generate TrainX and TrainY\n",
        "trainX, testX, trainY, testY = train_test_split(x, y, test_size= 1 - train_ratio)\n",
        "# Genearate ValX, TestX, ValY and TestY\n",
        "valX, testX, valY, testY = train_test_split(testX, testY, test_size=test_ratio/(test_ratio + validation_ratio))"
      ],
      "metadata": {
        "id": "QWYljmjhNXfh"
      },
      "id": "QWYljmjhNXfh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainX.shape)\n",
        "print(valX.shape)\n",
        "print(testX.shape)"
      ],
      "metadata": {
        "id": "Xx7lDjz8NI2j",
        "outputId": "26c251fa-e4bf-4ed9-b3f6-44591a85d142",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Xx7lDjz8NI2j",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(792, 17)\n",
            "(170, 17)\n",
            "(170, 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc=StandardScaler()\n",
        "\n",
        "scaler = sc.fit(trainX)\n",
        "\n",
        "trainX_scaled = scaler.transform(trainX)\n",
        "valX_scaled = scaler.transform(valX)\n",
        "testX_scaled = scaler.transform(testX)"
      ],
      "metadata": {
        "id": "eO5crVElRBRj"
      },
      "id": "eO5crVElRBRj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_no = 'ckpt_1_ANN'\n",
        "model_name = 'ANN_2FC_F64_64_epoch_120'"
      ],
      "metadata": {
        "id": "sATelL_lRDoc"
      },
      "id": "sATelL_lRDoc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = trainX.shape[1]\n",
        "\n",
        "n_batch_size = 128\n",
        "\n",
        "n_steps_per_epoch = int(trainX.shape[0] / n_batch_size)\n",
        "n_validation_steps = int(valX.shape[0] / n_batch_size)\n",
        "n_test_steps = int(testX.shape[0] / n_batch_size)\n",
        "\n",
        "n_epochs = 120\n",
        "\n",
        "\n",
        "print('Input Shape: ' + str(input_shape))\n",
        "print('Batch Size: ' + str(n_batch_size))\n",
        "print()\n",
        "print('Steps per Epoch: ' + str(n_steps_per_epoch))\n",
        "print()\n",
        "print('Validation Steps: ' + str(n_validation_steps))\n",
        "print('Test Steps: ' + str(n_test_steps))\n",
        "print()\n",
        "print('Number of Epochs: ' + str(n_epochs))"
      ],
      "metadata": {
        "id": "GQibbPgCRFLs",
        "outputId": "0c5ddd17-7b13-443e-9d67-d6a9105e71fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "GQibbPgCRFLs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Shape: 17\n",
            "Batch Size: 128\n",
            "\n",
            "Steps per Epoch: 6\n",
            "\n",
            "Validation Steps: 1\n",
            "Test Steps: 1\n",
            "\n",
            "Number of Epochs: 120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(input_shape,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(1))"
      ],
      "metadata": {
        "id": "Ty4hscn6RHou"
      },
      "id": "Ty4hscn6RHou",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "28Fj-kK5RSc_",
        "outputId": "67768e00-7553-4634-a757-b4fc9ff4c624",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "28Fj-kK5RSc_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_44\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_132 (Dense)           (None, 64)                1152      \n",
            "                                                                 \n",
            " dense_133 (Dense)           (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_134 (Dense)           (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_135 (Dense)           (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,537\n",
            "Trainable params: 9,537\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mse',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['mae'])"
      ],
      "metadata": {
        "id": "qvCtZqvSRUlt"
      },
      "id": "qvCtZqvSRUlt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = './'+ checkpoint_no\n",
        "if not os.path.exists(checkpoint_dir):\n",
        "    os.makedirs(checkpoint_dir)"
      ],
      "metadata": {
        "id": "8Q8FmiYARdOv"
      },
      "id": "8Q8FmiYARdOv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras_callbacks = [ModelCheckpoint(filepath = checkpoint_dir + '/' + model_name, \n",
        "                                   monitor='val_loss', save_best_only=True, mode='auto')]"
      ],
      "metadata": {
        "id": "2pUSsPQdRdng"
      },
      "id": "2pUSsPQdRdng",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(trainX_scaled,\n",
        "                    trainY,\n",
        "                    steps_per_epoch=n_steps_per_epoch,\n",
        "                    epochs=n_epochs,\n",
        "                    batch_size=n_batch_size,\n",
        "                    validation_data=(valX_scaled, valY),\n",
        "                    validation_steps=n_validation_steps,\n",
        "                    callbacks=[keras_callbacks])"
      ],
      "metadata": {
        "id": "ASb6NX2eRhk8",
        "outputId": "cd9d08b9-15e9-45e9-ee37-fa73ecd3d2f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ASb6NX2eRhk8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "6/6 [==============================] - 2s 173ms/step - loss: 41.6270 - mae: 6.4047 - val_loss: 31.6528 - val_mae: 5.5433\n",
            "Epoch 2/120\n",
            "6/6 [==============================] - 1s 142ms/step - loss: 23.9281 - mae: 4.7623 - val_loss: 17.7750 - val_mae: 3.9876\n",
            "Epoch 3/120\n",
            "6/6 [==============================] - 1s 144ms/step - loss: 12.4564 - mae: 3.2543 - val_loss: 8.6171 - val_mae: 2.5896\n",
            "Epoch 4/120\n",
            "6/6 [==============================] - 1s 141ms/step - loss: 5.6839 - mae: 1.9855 - val_loss: 5.2372 - val_mae: 1.8778\n",
            "Epoch 5/120\n",
            "6/6 [==============================] - 1s 142ms/step - loss: 4.0280 - mae: 1.6423 - val_loss: 3.7109 - val_mae: 1.5931\n",
            "Epoch 6/120\n",
            "6/6 [==============================] - 1s 145ms/step - loss: 2.8905 - mae: 1.3587 - val_loss: 2.7895 - val_mae: 1.3941\n",
            "Epoch 7/120\n",
            "6/6 [==============================] - 1s 200ms/step - loss: 2.2032 - mae: 1.1965 - val_loss: 2.1629 - val_mae: 1.2031\n",
            "Epoch 8/120\n",
            "6/6 [==============================] - 1s 142ms/step - loss: 1.7834 - mae: 1.0664 - val_loss: 1.7183 - val_mae: 1.0562\n",
            "Epoch 9/120\n",
            "6/6 [==============================] - 1s 156ms/step - loss: 1.3321 - mae: 0.9163 - val_loss: 1.4055 - val_mae: 0.9496\n",
            "Epoch 10/120\n",
            "6/6 [==============================] - 1s 143ms/step - loss: 1.2297 - mae: 0.8728 - val_loss: 1.1509 - val_mae: 0.8500\n",
            "Epoch 11/120\n",
            "6/6 [==============================] - 1s 140ms/step - loss: 1.1052 - mae: 0.8178 - val_loss: 1.0051 - val_mae: 0.7891\n",
            "Epoch 12/120\n",
            "6/6 [==============================] - 1s 140ms/step - loss: 0.9330 - mae: 0.7557 - val_loss: 0.8899 - val_mae: 0.7460\n",
            "Epoch 13/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.7927 - mae: 0.6905 - val_loss: 0.8903 - val_mae: 0.7258\n",
            "Epoch 14/120\n",
            "6/6 [==============================] - 1s 142ms/step - loss: 0.7464 - mae: 0.6713 - val_loss: 0.7217 - val_mae: 0.6918\n",
            "Epoch 15/120\n",
            "6/6 [==============================] - 1s 144ms/step - loss: 0.6669 - mae: 0.6272 - val_loss: 0.6981 - val_mae: 0.6439\n",
            "Epoch 16/120\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 0.6669 - mae: 0.6373 - val_loss: 0.6394 - val_mae: 0.6159\n",
            "Epoch 17/120\n",
            "6/6 [==============================] - 1s 141ms/step - loss: 0.5981 - mae: 0.6052 - val_loss: 0.5282 - val_mae: 0.5701\n",
            "Epoch 18/120\n",
            "6/6 [==============================] - 1s 206ms/step - loss: 0.5201 - mae: 0.5411 - val_loss: 0.5141 - val_mae: 0.5560\n",
            "Epoch 19/120\n",
            "6/6 [==============================] - 1s 145ms/step - loss: 0.4641 - mae: 0.5278 - val_loss: 0.4811 - val_mae: 0.5371\n",
            "Epoch 20/120\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5997 - mae: 0.5926 - val_loss: 0.5547 - val_mae: 0.5524\n",
            "Epoch 21/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3817 - mae: 0.4801 - val_loss: 0.5092 - val_mae: 0.5856\n",
            "Epoch 22/120\n",
            "6/6 [==============================] - 1s 145ms/step - loss: 0.4314 - mae: 0.5139 - val_loss: 0.4020 - val_mae: 0.4764\n",
            "Epoch 23/120\n",
            "6/6 [==============================] - 1s 142ms/step - loss: 0.3625 - mae: 0.4560 - val_loss: 0.3816 - val_mae: 0.4712\n",
            "Epoch 24/120\n",
            "6/6 [==============================] - 1s 144ms/step - loss: 0.4421 - mae: 0.5293 - val_loss: 0.3695 - val_mae: 0.4856\n",
            "Epoch 25/120\n",
            "6/6 [==============================] - 1s 141ms/step - loss: 0.3413 - mae: 0.4574 - val_loss: 0.3304 - val_mae: 0.4302\n",
            "Epoch 26/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3016 - mae: 0.4153 - val_loss: 0.3384 - val_mae: 0.4398\n",
            "Epoch 27/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2985 - mae: 0.4197 - val_loss: 0.3871 - val_mae: 0.4692\n",
            "Epoch 28/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3164 - mae: 0.4377 - val_loss: 0.3595 - val_mae: 0.4511\n",
            "Epoch 29/120\n",
            "6/6 [==============================] - 1s 138ms/step - loss: 0.2365 - mae: 0.3678 - val_loss: 0.2766 - val_mae: 0.3979\n",
            "Epoch 30/120\n",
            "6/6 [==============================] - 1s 136ms/step - loss: 0.3627 - mae: 0.4756 - val_loss: 0.2651 - val_mae: 0.3827\n",
            "Epoch 31/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2555 - mae: 0.3863 - val_loss: 0.4233 - val_mae: 0.5030\n",
            "Epoch 32/120\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2390 - mae: 0.3821 - val_loss: 0.2870 - val_mae: 0.3978\n",
            "Epoch 33/120\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2199 - mae: 0.3585 - val_loss: 0.3294 - val_mae: 0.4240\n",
            "Epoch 34/120\n",
            "6/6 [==============================] - 1s 142ms/step - loss: 0.2135 - mae: 0.3586 - val_loss: 0.2519 - val_mae: 0.3738\n",
            "Epoch 35/120\n",
            "6/6 [==============================] - 1s 200ms/step - loss: 0.2655 - mae: 0.3996 - val_loss: 0.2499 - val_mae: 0.3796\n",
            "Epoch 36/120\n",
            "6/6 [==============================] - 1s 140ms/step - loss: 0.1674 - mae: 0.3094 - val_loss: 0.2007 - val_mae: 0.3344\n",
            "Epoch 37/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1927 - mae: 0.3307 - val_loss: 0.3646 - val_mae: 0.4733\n",
            "Epoch 38/120\n",
            "6/6 [==============================] - 1s 142ms/step - loss: 0.1959 - mae: 0.3480 - val_loss: 0.1938 - val_mae: 0.3285\n",
            "Epoch 39/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1994 - mae: 0.3415 - val_loss: 0.2841 - val_mae: 0.4416\n",
            "Epoch 40/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2333 - mae: 0.3795 - val_loss: 0.1941 - val_mae: 0.3326\n",
            "Epoch 41/120\n",
            "6/6 [==============================] - 1s 145ms/step - loss: 0.1352 - mae: 0.2837 - val_loss: 0.1721 - val_mae: 0.3120\n",
            "Epoch 42/120\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2213 - mae: 0.3867 - val_loss: 0.1882 - val_mae: 0.3377\n",
            "Epoch 43/120\n",
            "6/6 [==============================] - 1s 142ms/step - loss: 0.1479 - mae: 0.2938 - val_loss: 0.1696 - val_mae: 0.3111\n",
            "Epoch 44/120\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1182 - mae: 0.2595 - val_loss: 0.2559 - val_mae: 0.3826\n",
            "Epoch 45/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2188 - mae: 0.3832 - val_loss: 0.2158 - val_mae: 0.3517\n",
            "Epoch 46/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1481 - mae: 0.3023 - val_loss: 0.2740 - val_mae: 0.4018\n",
            "Epoch 47/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1825 - mae: 0.3304 - val_loss: 0.2904 - val_mae: 0.4097\n",
            "Epoch 48/120\n",
            "6/6 [==============================] - 1s 144ms/step - loss: 0.1461 - mae: 0.3053 - val_loss: 0.1574 - val_mae: 0.2913\n",
            "Epoch 49/120\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1088 - mae: 0.2607 - val_loss: 0.3553 - val_mae: 0.5169\n",
            "Epoch 50/120\n",
            "6/6 [==============================] - 1s 139ms/step - loss: 0.1998 - mae: 0.3617 - val_loss: 0.1535 - val_mae: 0.2890\n",
            "Epoch 51/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0972 - mae: 0.2370 - val_loss: 0.2013 - val_mae: 0.3386\n",
            "Epoch 52/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2008 - mae: 0.3675 - val_loss: 0.3634 - val_mae: 0.4834\n",
            "Epoch 53/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1572 - mae: 0.3217 - val_loss: 0.1712 - val_mae: 0.3123\n",
            "Epoch 54/120\n",
            "6/6 [==============================] - 1s 141ms/step - loss: 0.0841 - mae: 0.2211 - val_loss: 0.1516 - val_mae: 0.2906\n",
            "Epoch 55/120\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1782 - mae: 0.3387 - val_loss: 0.2304 - val_mae: 0.3836\n",
            "Epoch 56/120\n",
            "6/6 [==============================] - 1s 135ms/step - loss: 0.1298 - mae: 0.2786 - val_loss: 0.1438 - val_mae: 0.2860\n",
            "Epoch 57/120\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0842 - mae: 0.2202 - val_loss: 0.1678 - val_mae: 0.3170\n",
            "Epoch 58/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1700 - mae: 0.3292 - val_loss: 0.3654 - val_mae: 0.5308\n",
            "Epoch 59/120\n",
            "6/6 [==============================] - 1s 192ms/step - loss: 0.1726 - mae: 0.3342 - val_loss: 0.1397 - val_mae: 0.2779\n",
            "Epoch 60/120\n",
            "6/6 [==============================] - 1s 137ms/step - loss: 0.0729 - mae: 0.2099 - val_loss: 0.1308 - val_mae: 0.2635\n",
            "Epoch 61/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0955 - mae: 0.2353 - val_loss: 0.1647 - val_mae: 0.3146\n",
            "Epoch 62/120\n",
            "6/6 [==============================] - 1s 141ms/step - loss: 0.2078 - mae: 0.3762 - val_loss: 0.1201 - val_mae: 0.2543\n",
            "Epoch 63/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0717 - mae: 0.2046 - val_loss: 0.1286 - val_mae: 0.2660\n",
            "Epoch 64/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1448 - mae: 0.3046 - val_loss: 0.2678 - val_mae: 0.4432\n",
            "Epoch 65/120\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1189 - mae: 0.2708 - val_loss: 0.1202 - val_mae: 0.2562\n",
            "Epoch 66/120\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1069 - mae: 0.2677 - val_loss: 0.1443 - val_mae: 0.2909\n",
            "Epoch 67/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1028 - mae: 0.2579 - val_loss: 0.1368 - val_mae: 0.2788\n",
            "Epoch 68/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1205 - mae: 0.2862 - val_loss: 0.1454 - val_mae: 0.2924\n",
            "Epoch 69/120\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1201 - mae: 0.2864 - val_loss: 0.1298 - val_mae: 0.2651\n",
            "Epoch 70/120\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1064 - mae: 0.2623 - val_loss: 0.1919 - val_mae: 0.3467\n",
            "Epoch 71/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1092 - mae: 0.2682 - val_loss: 0.1716 - val_mae: 0.3258\n",
            "Epoch 72/120\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1221 - mae: 0.2925 - val_loss: 0.2046 - val_mae: 0.3667\n",
            "Epoch 73/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1128 - mae: 0.2718 - val_loss: 0.1337 - val_mae: 0.2695\n",
            "Epoch 74/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0672 - mae: 0.2029 - val_loss: 0.1641 - val_mae: 0.3193\n",
            "Epoch 75/120\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1288 - mae: 0.2987 - val_loss: 0.1522 - val_mae: 0.3002\n",
            "Epoch 76/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1093 - mae: 0.2751 - val_loss: 0.1592 - val_mae: 0.3089\n",
            "Epoch 77/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1115 - mae: 0.2776 - val_loss: 0.1665 - val_mae: 0.3164\n",
            "Epoch 78/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0984 - mae: 0.2577 - val_loss: 0.1609 - val_mae: 0.3061\n",
            "Epoch 79/120\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0677 - mae: 0.2066 - val_loss: 0.1306 - val_mae: 0.2661\n",
            "Epoch 80/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1346 - mae: 0.3039 - val_loss: 0.2121 - val_mae: 0.3794\n",
            "Epoch 81/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1070 - mae: 0.2692 - val_loss: 0.1315 - val_mae: 0.2630\n",
            "Epoch 82/120\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0721 - mae: 0.2102 - val_loss: 0.1371 - val_mae: 0.2822\n",
            "Epoch 83/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1446 - mae: 0.3200 - val_loss: 0.1646 - val_mae: 0.3227\n",
            "Epoch 84/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0816 - mae: 0.2327 - val_loss: 0.1284 - val_mae: 0.2535\n",
            "Epoch 85/120\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0446 - mae: 0.1617 - val_loss: 0.1362 - val_mae: 0.2736\n",
            "Epoch 86/120\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2161 - mae: 0.3976 - val_loss: 0.2079 - val_mae: 0.3477\n",
            "Epoch 87/120\n",
            "6/6 [==============================] - 1s 142ms/step - loss: 0.0533 - mae: 0.1781 - val_loss: 0.1139 - val_mae: 0.2406\n",
            "Epoch 88/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0438 - mae: 0.1595 - val_loss: 0.1332 - val_mae: 0.2659\n",
            "Epoch 89/120\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1398 - mae: 0.3116 - val_loss: 0.2342 - val_mae: 0.3692\n",
            "Epoch 90/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0803 - mae: 0.2278 - val_loss: 0.1171 - val_mae: 0.2455\n",
            "Epoch 91/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0650 - mae: 0.2002 - val_loss: 0.2328 - val_mae: 0.3960\n",
            "Epoch 92/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1416 - mae: 0.3170 - val_loss: 0.1188 - val_mae: 0.2518\n",
            "Epoch 93/120\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0461 - mae: 0.1689 - val_loss: 0.1326 - val_mae: 0.2779\n",
            "Epoch 94/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1416 - mae: 0.3182 - val_loss: 0.1329 - val_mae: 0.2726\n",
            "Epoch 95/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0662 - mae: 0.2089 - val_loss: 0.1415 - val_mae: 0.2891\n",
            "Epoch 96/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0855 - mae: 0.2450 - val_loss: 0.1312 - val_mae: 0.2752\n",
            "Epoch 97/120\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1013 - mae: 0.2634 - val_loss: 0.1312 - val_mae: 0.2691\n",
            "Epoch 98/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0978 - mae: 0.2611 - val_loss: 0.1705 - val_mae: 0.3321\n",
            "Epoch 99/120\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0775 - mae: 0.2253 - val_loss: 0.1614 - val_mae: 0.3238\n",
            "Epoch 100/120\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1231 - mae: 0.3010 - val_loss: 0.1213 - val_mae: 0.2569\n",
            "Epoch 101/120\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0468 - mae: 0.1664 - val_loss: 0.1537 - val_mae: 0.2880\n",
            "Epoch 102/120\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1138 - mae: 0.2838 - val_loss: 0.2005 - val_mae: 0.3433\n",
            "Epoch 103/120\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0825 - mae: 0.2385 - val_loss: 0.1535 - val_mae: 0.2833\n",
            "Epoch 104/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0979 - mae: 0.2587 - val_loss: 0.2285 - val_mae: 0.3724\n",
            "Epoch 105/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0767 - mae: 0.2252 - val_loss: 0.1393 - val_mae: 0.2673\n",
            "Epoch 106/120\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0628 - mae: 0.2021 - val_loss: 0.2182 - val_mae: 0.3629\n",
            "Epoch 107/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1320 - mae: 0.3102 - val_loss: 0.1324 - val_mae: 0.2652\n",
            "Epoch 108/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0574 - mae: 0.1928 - val_loss: 0.1718 - val_mae: 0.3102\n",
            "Epoch 109/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1224 - mae: 0.2987 - val_loss: 0.2003 - val_mae: 0.3385\n",
            "Epoch 110/120\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0829 - mae: 0.2435 - val_loss: 0.1456 - val_mae: 0.2722\n",
            "Epoch 111/120\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0698 - mae: 0.2130 - val_loss: 0.2208 - val_mae: 0.3578\n",
            "Epoch 112/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1107 - mae: 0.2858 - val_loss: 0.1414 - val_mae: 0.2688\n",
            "Epoch 113/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0527 - mae: 0.1863 - val_loss: 0.1502 - val_mae: 0.2886\n",
            "Epoch 114/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1020 - mae: 0.2719 - val_loss: 0.1748 - val_mae: 0.3067\n",
            "Epoch 115/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0797 - mae: 0.2383 - val_loss: 0.1519 - val_mae: 0.2848\n",
            "Epoch 116/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0948 - mae: 0.2575 - val_loss: 0.1966 - val_mae: 0.3407\n",
            "Epoch 117/120\n",
            "6/6 [==============================] - 1s 146ms/step - loss: 0.0608 - mae: 0.1992 - val_loss: 0.1137 - val_mae: 0.2398\n",
            "Epoch 118/120\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0431 - mae: 0.1607 - val_loss: 0.2654 - val_mae: 0.4136\n",
            "Epoch 119/120\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1726 - mae: 0.3694 - val_loss: 0.1358 - val_mae: 0.2637\n",
            "Epoch 120/120\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0371 - mae: 0.1505 - val_loss: 0.1212 - val_mae: 0.2476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist_df = pd.DataFrame(history.history)\n",
        "hist_df['epoch'] = hist_df.index + 1\n",
        "cols = list(hist_df.columns)\n",
        "cols = [cols[-1]] + cols[:-1]\n",
        "hist_df = hist_df[cols]\n",
        "hist_df.to_csv(checkpoint_no + '/' + 'history_df_' + model_name + '.csv')\n",
        "hist_df.head()"
      ],
      "metadata": {
        "id": "-3pM5sK8Rorr",
        "outputId": "73f016ca-a297-492c-d033-6c574321206e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "id": "-3pM5sK8Rorr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   epoch       loss       mae   val_loss   val_mae\n",
              "0      1  41.627048  6.404726  31.652792  5.543263\n",
              "1      2  23.928120  4.762258  17.774973  3.987603\n",
              "2      3  12.456367  3.254271   8.617093  2.589633\n",
              "3      4   5.683879  1.985530   5.237187  1.877754\n",
              "4      5   4.028008  1.642322   3.710943  1.593099"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ed1e0b8-2397-4403-a388-08d05a14bf00\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>loss</th>\n",
              "      <th>mae</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_mae</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>41.627048</td>\n",
              "      <td>6.404726</td>\n",
              "      <td>31.652792</td>\n",
              "      <td>5.543263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>23.928120</td>\n",
              "      <td>4.762258</td>\n",
              "      <td>17.774973</td>\n",
              "      <td>3.987603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>12.456367</td>\n",
              "      <td>3.254271</td>\n",
              "      <td>8.617093</td>\n",
              "      <td>2.589633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>5.683879</td>\n",
              "      <td>1.985530</td>\n",
              "      <td>5.237187</td>\n",
              "      <td>1.877754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>4.028008</td>\n",
              "      <td>1.642322</td>\n",
              "      <td>3.710943</td>\n",
              "      <td>1.593099</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ed1e0b8-2397-4403-a388-08d05a14bf00')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8ed1e0b8-2397-4403-a388-08d05a14bf00 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8ed1e0b8-2397-4403-a388-08d05a14bf00');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values_of_best_model = hist_df[hist_df.val_loss == hist_df.val_loss.min()]\n",
        "values_of_best_model"
      ],
      "metadata": {
        "id": "D4QD_EcmRsGL",
        "outputId": "62fde254-cec8-42f1-b98e-576f30581c41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "id": "D4QD_EcmRsGL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     epoch     loss       mae  val_loss   val_mae\n",
              "116    117  0.06077  0.199206  0.113738  0.239779"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7221e0d8-2495-4330-bc45-bc6fefec52a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>loss</th>\n",
              "      <th>mae</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_mae</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>117</td>\n",
              "      <td>0.06077</td>\n",
              "      <td>0.199206</td>\n",
              "      <td>0.113738</td>\n",
              "      <td>0.239779</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7221e0d8-2495-4330-bc45-bc6fefec52a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7221e0d8-2495-4330-bc45-bc6fefec52a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7221e0d8-2495-4330-bc45-bc6fefec52a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pk.dump(scaler, open(checkpoint_no + '/' + 'scaler.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "mm4zTEvCRuyL"
      },
      "id": "mm4zTEvCRuyL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mae = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(mae) + 1)\n",
        "\n",
        "plt.plot(epochs, mae, 'bo', label='Training MAE')\n",
        "plt.plot(epochs, val_mae, 'b', label='Validation MAE')\n",
        "plt.title('Training and validation MAE')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oSc-INkrRxum",
        "outputId": "8f53f861-351b-44f2-b193-2e55c4c6191e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "id": "oSc-INkrRxum",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-fold cross validation"
      ],
      "metadata": {
        "id": "YA0o_NLo2RpX"
      },
      "id": "YA0o_NLo2RpX"
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(64, activation='relu',\n",
        "                           input_shape=(input_shape,)))\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(1))\n",
        "    model.compile(loss='mse', optimizer='rmsprop', metrics=['mae'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "wHGZzNSCYK6y"
      },
      "id": "wHGZzNSCYK6y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 5\n",
        "num_val_samples = len(trainX) // k"
      ],
      "metadata": {
        "id": "GW2xk5BiKVEI"
      },
      "id": "GW2xk5BiKVEI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_scores = []\n",
        "for i in range(k):\n",
        "    print('Processing Fold', i)\n",
        "    val_data = trainX_scaled[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    val_targets = trainY[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "\n",
        "    partial_train_data = np.concatenate(\n",
        "        [trainX_scaled[:i * num_val_samples],\n",
        "         trainX_scaled[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    partial_train_targets = np.concatenate(\n",
        "        [trainY[:i * num_val_samples],\n",
        "         trainY[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "\n",
        "    model = build_model()\n",
        "    model.fit(partial_train_data, partial_train_targets,\n",
        "              epochs=n_epochs, batch_size=n_batch_size, verbose=0)\n",
        "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "    all_scores.append(val_mae)\n",
        "    print('MAE: ' + str(val_mae))\n",
        "    print('----------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMjAgJ2TYIcK",
        "outputId": "24e4cb82-1b14-4567-f5f6-9e03def841fd"
      },
      "id": "SMjAgJ2TYIcK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 0\n",
            "MAE: 0.2929545044898987\n",
            "----------------------\n",
            "Processing Fold 1\n",
            "MAE: 0.2667238116264343\n",
            "----------------------\n",
            "Processing Fold 2\n",
            "MAE: 0.31392064690589905\n",
            "----------------------\n",
            "Processing Fold 3\n",
            "MAE: 0.28865838050842285\n",
            "----------------------\n",
            "Processing Fold 4\n",
            "MAE: 0.2778300642967224\n",
            "----------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, val in enumerate(all_scores):\n",
        "    print('Fold ' + str(i) +': ' + 'MAE of', val)"
      ],
      "metadata": {
        "id": "WPLyoiK6SF7Q",
        "outputId": "67614060-d1fc-4094-86db-1559bbb0cbb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "WPLyoiK6SF7Q",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0: MAE of 0.2929545044898987\n",
            "Fold 1: MAE of 0.2667238116264343\n",
            "Fold 2: MAE of 0.31392064690589905\n",
            "Fold 3: MAE of 0.28865838050842285\n",
            "Fold 4: MAE of 0.2778300642967224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Mean MAE of all folds: ' + str(np.mean(all_scores)))"
      ],
      "metadata": {
        "id": "ejTtKjkYSHoP",
        "outputId": "32ae857c-cee0-435d-b393-f8fc92ad92fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ejTtKjkYSHoP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean MAE of all folds: 0.28801748156547546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_mae_histories = []\n",
        "for i in range(k):\n",
        "    print('Processing Fold', i)\n",
        "    val_data = trainX_scaled[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    val_targets = trainY[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    partial_train_data = np.concatenate(\n",
        "        [trainX_scaled[:i * num_val_samples],\n",
        "         trainX_scaled[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    partial_train_targets = np.concatenate(\n",
        "        [trainY[:i * num_val_samples],\n",
        "         trainY[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "\n",
        "    model = build_model()\n",
        "    history = model.fit(partial_train_data, partial_train_targets,\n",
        "                        validation_data=(val_data, val_targets),\n",
        "                        epochs=n_epochs, batch_size=n_batch_size, verbose=0)\n",
        "    mae_history = history.history['val_mae']\n",
        "    all_mae_histories.append(mae_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isrp21LPKOzQ",
        "outputId": "23a47aaa-5a08-4744-f1d1-31ab51cf5349"
      },
      "id": "isrp21LPKOzQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 0\n",
            "Processing Fold 1\n",
            "Processing Fold 2\n",
            "Processing Fold 3\n",
            "Processing Fold 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(n_epochs)]\n",
        "\n",
        "len(average_mae_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGwfg_NmKQsb",
        "outputId": "2f842489-e161-4b75-f665-0655e88adf05"
      },
      "id": "FGwfg_NmKQsb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\n",
        "plt.title('Validation MAE per Epoch')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation MAE')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "80oxRyHSP8Oe",
        "outputId": "9b8e1e26-5d79-410b-ff36-7b089118be95"
      },
      "id": "80oxRyHSP8Oe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def smooth_curve(points, factor=0.9):\n",
        "      '''\n",
        "      Function for smoothing data points\n",
        "\n",
        "      Args:\n",
        "          points (float64): Array of floats to be smoothed, numpy array of floats\n",
        "\n",
        "      Returns:\n",
        "          Smoothed data points\n",
        "      '''  \n",
        "      smoothed_points = []\n",
        "      for point in points:\n",
        "        if smoothed_points:\n",
        "          previous = smoothed_points[-1]\n",
        "          smoothed_points.append(previous * factor + point * (1 - factor))\n",
        "        else:\n",
        "          smoothed_points.append(point)\n",
        "      return smoothed_points"
      ],
      "metadata": {
        "id": "hITi0gvsekb-"
      },
      "id": "hITi0gvsekb-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_first_observations_to_exclude = 30\n",
        "\n",
        "smooth_mae_history = smooth_curve(average_mae_history[n_first_observations_to_exclude:])\n",
        "\n",
        "smooth_mae_history = pd.DataFrame(smooth_mae_history)\n",
        "smooth_mae_history = smooth_mae_history.set_index(smooth_mae_history.index + n_first_observations_to_exclude)\n",
        "smooth_mae_history.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "C7inuCGmfEmf",
        "outputId": "19fb269e-5c91-488d-8e3b-f5b6a184a9e0"
      },
      "id": "C7inuCGmfEmf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0\n",
              "30  0.489379\n",
              "31  0.488464\n",
              "32  0.487497\n",
              "33  0.484723\n",
              "34  0.482996"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ec4525f1-32fc-4240-ba30-701547927f9f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.489379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.488464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.487497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.484723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.482996</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec4525f1-32fc-4240-ba30-701547927f9f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ec4525f1-32fc-4240-ba30-701547927f9f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ec4525f1-32fc-4240-ba30-701547927f9f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(smooth_mae_history)\n",
        "plt.title('Validation MAE per Epoch')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation MAE')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "N0Eo9ZUXff48",
        "outputId": "7b8dcc41-ac05-46a1-e6a1-3a271a31b2de"
      },
      "id": "N0Eo9ZUXff48",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xV9f3H8dc7g7B32BsCsmRFRetWFAXR1gUO0P7UOlDraKtVax0ddljrqIqrYgW11kHrwIkWFSEM2SPsKTPsleTz++Oc2EtMwg3k5ia5n+fjcR6553vO+d7PPVzyyfd7zvl+ZWY455xz0UqKdwDOOecqF08czjnnSsUTh3POuVLxxOGcc65UPHE455wrFU8czjnnSsUTh6swJJmkTuHrpyTdE82+h/A+l0r64FDjdLEn6e+SHox3HK5onjhcmZH0vqT7iyg/V9I6SSnR1mVm15rZA2UQU7swyXz33mb2spmdcbh1F/FeJ4fv9Wah8l5h+YRC5ZK0RNLcIuqaIGmPpB0Ry7/LOuZoSPq1pP2FYsmJRyyuYvDE4crSi8BlklSo/HLgZTPLjUNM5W0DcKykRhFlI4CFRex7ItAE6CDpqCK2jzSz2hHLOTGI9wAlJPdXC8VSP9axuIrLE4crS28BjYATCgokNQAGA6MlHS3pK0k5ktZKelxStaIqKtxVIeln4TFrJP240L6DJE2XtE3SSkm/jtj8efgzJ/xL+VhJV0iaGHH8cZKmSNoa/jwuYtsESQ9I+kLSdkkfSGpcwjnYF56HoeHxycDFwMtF7DsCeBt4N3x9SMLP80V4PrdKmi/ptIjt9SQ9F56/1ZIeDOOKPPYvkjYBvz6E9zdJN4Wtp42S/igpKdyWJOluScslrZc0WlK9iGOPl/Rl+J1YKemKiKobSHonPO9fS+p4qOfIlS1PHK7MmNlu4DVgeETxRcB8M/sGyANuARoDxwKnAdcfrF5JA4HbgQFABnB6oV12hu9ZHxgEXCfpvHDbieHP+uFfyl8Vqrsh8A7wKEHSexh4p1CL4RLgSoLWQbUwlpKM5n/n4ExgNrCm0PvWBC4gSCgvA0OLS6JROgZYTHBu7wXeCD8bwN+BXKAT0Ac4A7iq0LFLgKbAbw7x/X8IZAJ9gXOBguR+RbicAnQAagOPA0hqC7wHPAakA72BGRF1DgXuAxoA2YcRmytjnjhcWXsRuEBS9XB9eFiGmU01s0lmlmtmy4CngZOiqPMi4AUzm21mOyn0V7GZTTCzWWaWb2YzgbFR1gtBollkZi+FcY0F5gOR3UIvmNnCiMTYu6QKzexLoKGkLgSff3QRu/0I2At8QJC4UsNYIj0a/iVesJR0zWc98IiZ7TezV4EFwCBJTYGzgZ+a2U4zWw/8hbBFFFpjZo+Fn393MfVfVCiWTwttf8jMNpvZCuARYFhYfinwsJktMbMdwJ0ESTKFICF/ZGZjw7g3mVlk4njTzCaHXZwvc5Dz7spP1BcrnYuGmU2UtBE4T9IU4GiCX5JI6kzwF30mUJPg+zc1impbFNpveeRGSccAvwd6ELQI0oB/Rhlyi8L1hestI9bXRbzeRfBX88G8BIwk+Ev7xwS/JCONAF4LfynmSvpXWBZ5Yf0mM3s2ivcCWG0Hjli6nOCztSVISmsjLj0lASsj9o18XZzXzOyyErZH1lHw3vD987uc4N+9KdCaoJVUnEM5764ceIvDxUJBV81lwHgz+zYsf5Lgr/kMM6sL/BIofCG9KGsJfskUaFNo+xhgHNDazOoBT0XUe7Dhn9cQ/HKN1AZYHUVcJXmJoBvuXTPbFblBUivgVIIbCdZJWkfQbXX2Qa6flKRloZsS2hB8tpUELZvGZlY/XOqaWfeIfctiiOzC/z4FXXOFz28bgm6zb8PY/LpFJeSJw8XCaILrEFcTdlOF6gDbgB2SjgCui7K+14ArJHULrw3cW2h7HWCzme2RdDQH/nW/Acgn6F8vyrtAZ0mXSEqRdDHQDfhPlLEVycyWEnSX3VXE5ssJ7rLqQtD90hvoDKzif108pdUEuElSqqQLga4ESWstQXfYnyXVDS9Wd5QUbVdetH4mqYGk1sDNwKth+VjgFkntJdUGfktwh1ZB99Ppki4Kz30jSd4dVQl44nBlLrx+8SVQi6AlUOB2gl/q24Fn+N8vl4PV9x5Bv/knBBdJPym0y/XA/ZK2A78iSDQFx+4iuKj6Rdg3379Q3ZsI7vq6DdgE/BwYbGYbo4ntIHFPNLM1RWwaAfzNzNZFLgQtpci7qx7Xgc9OlNSt9zXBjQMbCT7vBeFng6D1Vw2YC2wBXgeal/LjXFwolh2SmkRsf5ugO3EGwTWb58Ly5wlaX58DS4E9wI0A4fWQswnO/ebw2F6ljMvFgXwiJ+cqt/AW1qvM7Pg4vb8RdD9mx+P9XfnzFodzzrlS8cThnHOuVLyryjnnXKl4i8M551ypJMQDgI0bN7Z27drFOwznnKtUpk6dutHM0guXJ0TiaNeuHVlZWfEOwznnKhVJhUdVALyryjnnXCl54nDOOVcqnjicc86ViicO55xzpeKJwznnXKl44nDOOVcqnjicc86VSkI8x3GoXvhiKXWqp3JS53TS66TFOxznnKsQPHEUw8wYO3kFC7/dAUCvVvU45YgmnN61Kd1b1OXAydaccy5xJMQgh5mZmXYoT47n5xtz127j0/nr+XTBeqavzMEMWtSrzundmnL1CR1o3bBmDCJ2zrn4kzTVzDK/V+6JI3obd+zlk3nr+XDet3y+cAO10lJ4bkQmfdo0KIMonXOuYikucfjF8VJoXDuNi45qzTPDM3nv5hOonZbCsGcm8eHcb+MdmnPOlRtPHIeoQ3pt3rj+OLo0rcNPXsriuYlLycuv+q0355zzxHEYGtdOY+w1/TmlSxMe+M9cBj82kc8Xboh3WM45F1OeOA5TzWopPDM8k0eH9WHH3v0Mf34ylz/3NYu+3R7v0JxzLiY8cZSBpCQxpFcLPrr1JO4e1JWZq7Zy9qP/5c8fLGDP/rx4h+ecc2XKE0cZSktJ5qoTOvDxbSdxzpEteOyTbM585HO+Wrwp3qE551yZ8cQRA41rp/Hwxb15+apjSJK49NlJPDdxKYlw67NzrurzxBFDP+jUmP/ceDwDujXlgf/M5Wevz2RvrnddOecqN08cMVYrLYUnL+3Hzadl8PrUVQwbNYmtu/bHOyznnDtknjjKQVKSuGVAZ/52aV9mr97GVaOn+EVz51ylFdPEIWmgpAWSsiXdUcJ+50sySZnh+qWSZkQs+ZJ6h9smhHUWbGsSy89Qls7u2ZyHL+5F1vIt3Dh2Orl5+fEOyTnnSi1miUNSMvAEcBbQDRgmqVsR+9UBbga+Ligzs5fNrLeZ9QYuB5aa2YyIwy4t2G5m62P1GWJh8JEt+PU53flw7rfc8/Zsv2DunKt0YtniOBrINrMlZrYPeAU4t4j9HgAeAvYUU8+w8NgqY8Rx7Rh5SifGTl7J79+f78nDOVepxDJxtARWRqyvCsu+I6kv0NrM3imhnouBsYXKXgi7qe5RMRNjSLpGUpakrA0bKt4wILed0ZlLj2nD058t4cF35nnycM5VGnGbyElSEvAwcEUJ+xwD7DKz2RHFl5rZ6rCL618EXVmjCx9rZqOAURAMq16GoZcJSTx4Xg9Sk5N4buJS9ubmcf+QHiQl+QRRzrmKLZaJYzXQOmK9VVhWoA7QA5gQNhqaAeMkDTGzgskzhlKotWFmq8Of2yWNIegS+17iqAwkce853UhLTeLpz5aQm2f87kc9fXZB51yFFsvEMQXIkNSeIGEMBS4p2GhmW4HGBeuSJgC3FySNsEVyEXBCxD4pQH0z2ygpFRgMfBTDzxBzkrhj4BEkS/xtwmKOz2jM4CNbxDss55wrVsyucZhZLjASGA/MA14zszmS7pc0JIoqTgRWmtmSiLI0YLykmcAMgoT0TBmHXu4kcdsZXejZsh73/3su2/b4A4LOuYrLp46tQGauyuHcJ75gxLHt+PWQ7vEOxzmX4Hzq2ErgyFb1Gd6/LS9+tYyZq3LiHY5zzhXJE0cFc9uZXUivncYv35zlU9E65yokTxwVTN3qqfzqnG7MXr2NJydkxzsc55z7Hk8cFdCgns05t3cL/vTBQt6fvS7e4Tjn3AE8cVRAknjo/CPp3bo+t7w6g9mrt8Y7JOec+44njgqqemoyo4b3o0HNVK4encX67cUN5eWcc+XLE0cF1qROdZ4ZkUnOrv3c8PI0H8/KOVcheOKo4Lq3qMd9Q7ozZdkW3pm1Nt7hOOecJ47K4Px+rTiiWR3+8P4Cn7PcORd3njgqgeQkcefZXVmxeRf/mLQi3uE45xKcJ45K4qTO6ZyQ0ZjHPlnE1t0+lpVzLn48cVQid5x1BFt37+dv/mCgcy6OPHFUIt1b1OOHfVrywhfLWLl5V7zDcc4lKE8clcztZ3ShWnISv/jXTPJ9LCvnXBx44qhkWtSvwT2Du/Ll4k2M/mpZvMNxziUgTxyV0EWZrTmlSzq/f38+SzbsiHc4zrkE44mjEpLE788/krSUZG775zc+/Lpzrlx54qikmtatzv3ndmf6ihwe+2RRvMNxziWQmCYOSQMlLZCULemOEvY7X5JJygzX20naLWlGuDwVsW8/SbPCOh+VpFh+hopsSK8W/LBPSx75aBFPf7Y43uE45xJESqwqlpQMPAEMAFYBUySNM7O5hfarA9wMfF2oisVm1ruIqp8Erg73fxcYCLxXxuFXCpL4wwVHsi8vn9+9N5/cfOOGUzrFOyznXBUXyxbH0UC2mS0xs33AK8C5Rez3APAQcNBxwyU1B+qa2SQLhoodDZxXhjFXOqnJSfz14t6c27sFfxy/gL9+5N1WzrnYimXiaAmsjFhfFZZ9R1JfoLWZvVPE8e0lTZf0maQTIupcVVKdEXVfIylLUtaGDRsO+UNUBinJSTx8UW9+1Lclf/loIZ/OXx/vkJxzVVjcLo5LSgIeBm4rYvNaoI2Z9QFuBcZIqlua+s1slJllmllmenr64QdcwSUnid//6Eg6pNfi1/+ew579Poqucy42Ypk4VgOtI9ZbhWUF6gA9gAmSlgH9gXGSMs1sr5ltAjCzqcBioHN4fKsS6kxo1VKSuG9Id5Zv2sUzny+JdzjOuSoqloljCpAhqb2kasBQYFzBRjPbamaNzaydmbUDJgFDzCxLUnp4cR1JHYAMYImZrQW2Seof3k01HHg7hp+h0jkhI52zejTjiQnZrNri41k558pezBKHmeUCI4HxwDzgNTObI+l+SUMOcviJwExJM4DXgWvNbHO47XrgWSCboCWSkHdUleTuwd0Q4oH/zD34zs45V0pKhHmsMzMzLSsrK95hlKsnPs3mj+MX8MKVR3FKlybxDsc5VwlJmmpmmYXL/cnxKuqqE9rTqUltfv76TDbu2BvvcJxzVYgnjioqLSWZR4f2Yevu/dz+z298CHbnXJnxxFGFdWtRl3sGdWXCgg08N3FpvMNxzlURnjiquMv6t+XM7k156P35fLMyJ97hOOeqAE8cVZwk/nB+L5rWrc6NY6ezfc/+eIfknKvkPHEkgHo1U3l0WG9W5+zmrjdnkwh30jnnYscTR4Lo17YhPz0tg3HfrOH1qasOfoBzzhXDE0cCuf6UTvTv0JB7x81hsU8565w7RJ44Ekhyknjk4j5US0niprHT2ZvrAyE650rPE0eCaVavOn+8oBdz1mzjttd8vnLnXOl54khAA7o15c6zjuA/M9dy15uz/GK5c65UYjZ1rKvYfnJSR7bvyeXxT7OpnZbCXYO6ksDTtzvnSsETRwK77YzO7Niby7MTl1K/ZiojT82Id0jOuUrAE0cCk8SvBncjZ9c+/vzhQjLbNaR/h0bxDss5V8H5NY4El5QkfvPDnrRtWJNbX53B1t3+ZLlzrmTFJg5Jr0W8fqjQtg9iGZQrX7XSUnhkaB++3b6XX709O97hOOcquJJaHJEd3gMKbUuPQSwujnq3rs9PT8vg7RlreHuGT+PunCteSYmjpHs0/f7NKui6kzvSr20D7n5zNqtzdsc7HOdcBVVS4qgpqY+kfkCN8HXfgvVoKpc0UNICSdmS7ihhv/MlmaTMcH2ApKmSZoU/T43Yd0JY54xw8XlRy0hKchKPXNybfDN+5pM/OeeKUdJdVWuBh8PX6yJeF6yXSFIy8ARBN9cqYIqkcWY2t9B+dYCbga8jijcC55jZGkk9gPFAy4jtl5pZYk0iXk5aN6zJ3YO7cecbsxj91TKu+EH7eIfknKtgik0cZnZKcdskpUZR99FAtpktCY95BTgXmFtovweAh4CfRbz39IjtcwhaPGlm5pNnl4OhR7Vm/Jx1/P79+ZzYOZ0O6bXjHZJzrgKJ+nZcBU6T9BxBC+JgWgIrI9ZXcWCrAUl9gdZm9k4J9ZwPTCuUNF4Iu6nuUTGPO0u6RlKWpKwNGzZEEa4rIImHzj+StJRkbn3tG3Lz8uMdknOuAjlo4pDUX9KjwHLgbeBz4IjDfWNJSQTdX7eVsE93gtbITyKKLzWznsAJ4XJ5Ucea2SgzyzSzzPR0vwmstJrWrc4D5/Vgxsocnv58SbzDcc5VICU9x/FbSYuA3wAzgT7ABjN70cy2RFH3aqB1xHqrsKxAHaAHMEHSMqA/MC7iAnkr4E1guJktLjjIzFaHP7cDYwi6xFwMDOnVgrN7NuOvHy0ie/32eIfjnKsgSmpxXAV8CzwJvGRmmyjdbbhTgAxJ7SVVA4YC4wo2mtlWM2tsZu3MrB0wCRhiZlmS6gPvAHeY2RcFx0hKkdQ4fJ0KDAb8ibUYum9ID2qmJfPz12f6EOzOOaDkxNEceBA4B1gs6SWCi9RRjW9lZrnASII7ouYBr5nZHEn3SxpykMNHAp2AXxW67TYNGC9pJjCDoAXzTDTxuEOTXieNXw3uxrQVOYz+alm8w3HOVQCKZi4GSWkEf90PI7iu8LGZXRLj2MpMZmamZWX53buHysy48u9T+HrJZj645URaN6wZ75Ccc+VA0lQzyyxcHtVdVWa218z+ZWYXELQE3i/rAF3FJYnf/rAnyUnizjd84ifnEl2x3U6Sbi3PQFzF1qJ+DX5x1hHc89Zs3p6xhvP6tDz4Qc65KqmkFsefgMuARkBtgrugChZ/IiwBXXJ0G3q1qseD78xj2x4fft25RFVS4ugDfAAMAtoCXwD3m9l9ZnZ/eQTnKpbkJPHgeT3ZtHMvD3+wMN7hOOfipNjEYWbfmNkdZtYbeI5wuJAo7ohyVVjPVvW47Ji2jP5qGbNXb413OM65OIjmyfF0gtZHT4JhQ9bHOihXsd1+Rhca1KzGPW/P9hF0nUtAJT05/mNJ7wP/BARcZGYDzGxSuUXnKqR6NVO58+yuTF+Rw4tfLYt3OM65clbSw3zPEjyVvRw4EzgjcjxBM/MuqwR2ft+WvDdrLQ/8Zy7tGtfilC4+LYpziaKkxFHssOrOSeLRYX246OmvGPnyNP557XF0a1E33mE558pBVE+OV3b+5HjsrNu6h/OeCIYTe+uGH9CsXvU4R+ScKyuH9eS4c8VpVq86z19xFNv37OeSZycxacmmeIfknIsxTxzusHVrUZdnRxzF3v35DB01iZFjprEmZ3e8w3LOxYgnDlcmju3YiI9uPYmfnp7Bh3O/5bQ/f8bnC33mReeqomie4+gs6RlJH0j6pGApj+Bc5VKjWjI/Pb0zH992Em0b1eSGMdNYvGFHvMNyzpWxaFoc/wSmAXcDP4tYnCtSqwY1eXZEJtWSk7jqxSy27vJxrZyrSqJJHLlm9qSZTTazqQVLzCNzlVqrBjV5+vJ+rNqyixvGTCM3Lz/eITnnykg0iePfkq6X1FxSw4Il5pG5Si+zXUN++8OeTMzeyIPvzIt3OM65MhLNNLAjwp+R3VMGdCj7cFxVc2Fmaxas286zE5fSrXldLjqqdbxDcs4dpoO2OMysfRFLVElD0kBJCyRlS7qjhP3Ol2SSMiPK7gyPWyDpzNLW6SqOO846ghMyGnP3W7OZunxLvMNxzh2maO6qSpV0k6TXw2WkpNQojksGngDOAroBwyR1K2K/OsDNwNcRZd2AoUB3YCDwN0nJ0dbpKpaU5CQeG9aH5vWrc+0/prJu6554h+ScOwzRXON4EugH/C1c+oVlB3M0kG1mS8xsH/AKwZwehT0APARE/jY5F3glnOt8KZAd1hdtna6CqV+zGs8Mz2TX3lx+8lIWe/bnxTsk59whiiZxHGVmI8zsk3C5EjgqiuNaAisj1leFZd+R1BdobWbvRHnsQeuMqPsaSVmSsjZs8AfRKoLOTevwl4t7882qrfzyjVkkwjhpzlVF0SSOPEkdC1YkdQAO+89FSUnAw8Bth1tXUcxslJllmllmenp6LN7CHYIzujfjltM788b01Tw3cWm8w3HOHYJo7qr6GfCppCUEEzq1Ba6M4rjVQOQtNK3CsgJ1gB7AhHCej2bAuHBq2pKOLalOVwnceGon5q/bxm/fnUfnpnU4sbMnducqk2juqvoYyABuAm4EupjZp1HUPQXIkNReUjWCi93jIurdamaNzaydmbUDJgFDzCwr3G+opDRJ7cP3n3ywOl3lkJQk/nRhLzo3rcPIMdNYunFnvENyzpVCSVPHnhr+/BEwCOgULoPCshKZWS4wEhgPzANeM7M5ku4PWxUlHTsHeA2YC7wP3GBmecXVefCP6SqaWmkpPDM8k6QkcePYaezL9SfLnassip3ISdJ9ZnavpBeK2Gxm9uPYhlZ2fCKnimv8nHX85KWpXH9yR34+8Ih4h+Oci1DcRE7FXuMws3vDl/eHt8RGVta+jONzCerM7s24OLM1T322mFOOaMJR7Xw0G+cqumjuqvpXEWWvl3UgLnHdc043WjWoyS2vzmD7Hh9J17mKrqRrHEdIOh+oJ+lHEcsVgE8s7cpM7bQU/nJxb9bk7Obet+f48x3OVXAl3Y7bBRgM1AfOiSjfDlwdy6Bc4unXtgE3nprBXz9eRIv6Nbj9zC7xDsk5V4ySrnG8Dbwt6Vgz+6ocY3IJ6ubTMli/fQ+Pf5pNWkoSN56WEe+QnHNFiOYBwOmSbiAYcPC7LqrKdFeVqxySksRvzuvJvlzjzx8upFpKEj85qePBD3TOlatoLo6/RPBU95nAZwRPa2+PZVAucSUliT9ccCTn9GrB796bz1UvTuH92ev8OQ/nKpBoWhydzOxCSeea2YuSxgD/jXVgLnElJ4mHL+pF+0Y1eWXKSj6at54GNVO57uSOXHOit0Cci7doWhwF90fmSOoB1AOaxC4k5yA1OYlbz+jCl3ecygtXHkWPlvX47bvz+XLxxniH5lzCiyZxjJLUALiHYFyoucAfYhqVc6GU5CRO6dKEUZdn0qZhTX75xiyfy8O5OItmkMNnzWyLmX1mZh3MrImZPVUewTlXoEa1ZH77w54s27SLRz9eFO9wnEtoxV7jkHRrSQea2cNlH45zxTs+ozHn923FqM+XcE6vFnRtXjfeITmXkEpqcdQJl0zgOv43A9+1QN/Yh+bc9909qCv1aqRyx79mkpfvT5g7Fw/FJg4zu8/M7iO4/bavmd1mZrcRzDneprwCdC5Sg1rV+NU53fhm1Vb+8uHCeIfjXEKK5uJ4U2BfxPq+sMy5uBjSqwUXZ7bm8U+zeW/W2niH41zCieY5jtHAZElvhuvnAX+PWUTOHYQk7j+vOwvXb+e2f35Dh/TadGlWJ95hOZcwormr6jcEc4xvCZcrzex3sQ7MuZKkpSTz1GX9qJWWwjUvZbF1lw/H7lx5KWlY9brhz4bAMoKhR14ClodlzsVV07rVeeqyvqzJ2c2IFyazftueeIfkXEIoqcUxJvw5FciKWArWnYu7fm0b8tiwvixYt50hj3/BNytz4h2Sc1VeSXdVDQ5/tg8f/CtY2ptZh2gqlzRQ0gJJ2ZLuKGL7tZJmSZohaaKkbmH5pWFZwZIvqXe4bUJYZ8E2H/4kwQ3s0Yx/XXccKcniwqe/4o1pq+IdknNVmoqbbU1Sic9qmNm0EiuWkoGFwABgFTAFGGZmcyP2qWtm28LXQ4DrzWxgoXp6Am+ZWcdwfQJwu5lF3erJzMy0rCxvJFV1m3fu4/qXpzJpyWZGntKJWwd0JilJ8Q7LuUpL0lQzyyxcXtJdVX8uYZsBpx7kPY8Gss1sSRjAK8C5BGNdBZWESSNUK6y3sGHAKwd5L+doWKsaL/3fMdzz1mwe/zSb5Zt38ccLjqR6anK8Q3OuSilpBsBTDrPulsDKiPVVwDGFdwoniboVqEbRyehigoQT6QVJecC/gAetiGaTpGuAawDatPHnFRNFanISv/tRT9o2qsVD789nbc5uRg3PpGGtavEOzbkqI5oHAJHUQ9JFkoYXLGUVgJk9EXZD/QK4u9D7HgPsMrPZEcWXmllP4IRwubyYekeZWaaZZaanp5dVuK4SkMR1J3fkiUv6MnP1Vq78+xR27/MRdZ0rKwdNHJLuBR4Ll1MIhlQfEkXdq4HWEeutwrLivELwcGGkocDYyAIzWx3+3E5w59fRUcTiEtCgI5vz2LA+zFyVw62vzSDfx7ZyrkxE0+K4ADgNWGdmVwK9CCZzOpgpQIak9pKqESSBcZE7SMqIWB0ELIrYlgRcRMT1DUkpkhqHr1OBwUBka8S5A5zZvRl3nd2V92av46Hx8+MdjnNVQjRDjuw2s3xJueFDges5sCVRJDPLlTQSGA8kA8+b2RxJ9wNZZjYOGCnpdIJZBrcAIyKqOBFYWXBxPZQGjA+TRjLwEfBMFJ/BJbD/O749yzbt5OnPltC2YS0uOcaveTl3OKJJHFmS6hP8gp4K7AC+iqZyM3sXeLdQ2a8iXt9cwrETgP6FynYSjM7rXNQk8etzurNqy27uemsW+WZc1r9tvMNyrtIqaciRJyT9wMyuN7OccNa/AcCIsMvKuUojJTmJJy/txyldmnD3W7N59ONFFPcMk3OuZCVd41gI/EnSMkl/kNTHzJaZ2czyCs65slSjWjJPX96PH/VpycMfLuS+f88lNy8/3mE5V+mU9BzHX4G/SmpLcGH7eUk1CO5yGmtmPouOq3RSk5P404W9aFCrGs9NXMp7s9dyft9WXJjZmvaNa8U7POcqhc1ixaAAABYwSURBVGKHHClyZ6kP8DxwpJlVmsdxfcgRV5iZ8dG89YydvIIJC9aTb3BBv1b88YIjkXyYEufg0IYcKTgwBTiLoNVxGjAB+HUZx+dcuZLEgG5NGdCtKd9u28OTExbz9y+X0at1fS73C+fOlajYxCFpAME4UWcDkwmep7gmvLPJuSqjad3q/GpwN5Zu3MmD/5nL0e0a+oyCzpWgpIvjdwJfAl3NbIiZjfGk4aqqpCTxpwt7Uad6KjeOncae/T5EiXPFKWk+jlPN7Fkz21KeATkXL+l10vjzRb1Y+O0OfvPOvHiH41yFFdUgh84lipM6p3PV8e15adJy/jh+Pnk+vpVz3xPNk+POJZSfDzyCHXtzeeLTxcxds41HhvahXo3UeIflXIXhLQ7nCqmWEszp8eB5Pfjvoo2c98QXzF+37eAHOpcgPHE4VwRJXNa/LWOu7s/2PfsZ/OhEfvfePHbuzY13aM7FnScO50pwdPuGjP/pifywT0ue/mwJAx7+jPFz1sU7LOfiyhOHcwfRqHYaf7ywF69feyx1a6Tyk5em8ss3Z/ktuy5heeJwLkqZ7Rry7xuP59qTOjLm6xX86G9fsmyjP9rkEo8nDudKITU5iTvOOoLnRmSyOmc3gx+byNszSpoR2bmqxxOHc4fgtK5NeffmE+jctDY3vzKDG8dOZ+uu/fEOy7ly4YnDuUPUsn4NXvvJsdx+Rmfem7WWMx/5nImLNsY7LOdiLqaJQ9JASQskZUu6o4jt10qaJWmGpImSuoXl7STtDstnSHoq4ph+4THZkh6Vj4Ht4iglOYmRp2bwxvXHUTMtmcue+5q73pzFDr9t11VhMUsckpKBJwiGZO8GDCtIDBHGmFlPM+sN/AF4OGLbYjPrHS7XRpQ/CVwNZITLwFh9BueidWSr+rx70wlcfUJ7xkxewZl/+Zz/LtoQ77Cci4lYtjiOBrLNbImZ7SMYlv3cyB3MLPJx3FpAiQMDSWoO1DWzSRbMQDUaOK9sw3bu0FRPTeauQd14/drjSEtN4vLnJjP6q2XxDsu5MhfLxNESWBmxviosO4CkGyQtJmhx3BSxqb2k6ZI+k3RCRJ2rDlZnWO81krIkZW3Y4H/5ufLTr20D3r3pBE7v2oR7x83h39+siXdIzpWpuF8cN7MnzKwj8Avg7rB4LdDGzPoAtwJjJNUtZb2jzCzTzDLT09PLNmjnDqJ6ajKPX9KXzLYNuPW1Gd5t5aqUWCaO1UDriPVWYVlxXiHsdjKzvWa2KXw9FVgMdA6Pb1WKOp2Lm+qpyTw74ig6ptfmJy9NZcbKnHiH5FyZiGXimAJkSGovqRrBnOXjIneQlBGxOghYFJanhxfXkdSB4CL4EjNbC2yT1D+8m2o48HYMP4Nzh6VejVRG//hoGtWuxojnJzNnzdZ4h+TcYYtZ4jCzXGAkMB6YB7xmZnMk3S9pSLjbSElzJM0g6JIaEZafCMwMy18HrjWzzeG264FngWyClsh7sfoMzpWFJnWrM+aq/tROS+GyZ79m3lofot1VbgpuTqraMjMzLSsrK95huAS3fNNOho6axN7cfMZe3Z8uzerEOyTnSiRpqpllFi6P+8Vx5xJF20a1GHt1f1KTxYVPfclNY6fz4pfLmLVqK/k+Ra2rRHzqWOfKUbvGtXjlmmP50wcL+HrpJsaFt+oO6tmcx4b1ISnJB0JwFZ8nDufKWfvGtXjikr6YGWu27uHVySt49JNsWjaowS/P7hrv8Jw7KE8czsWJJFrWr8EtAzqzdfd+Rn2+hNYNa3J5/7bxDs25EnnicC7OJPGrc7qzastu7n17Ni3rV+fUI5rGOyzniuUXx52rAJKTxKPD+tC1eV2uHj2VW1+bQfb6HfEOy7kieeJwroKolZbCP/7vGK44rh3vzlrLgL98xvUvT2X5Jp+e1lUs/hyHcxXQph17ef6Lpbz45XLyzfjl2V259Jg2+PQzrjz5cxzOVSKNaqfxszOP4INbTqRvmwbc/dZshj8/mTU5u+MdmnOeOJyryFrUr8FL/3c0D5zXg6xlWzjpj59y/ctT+e+iDf7QoIsbv6vKuQpOEpf3b8vJndN58ctlvD5tFe/OWkfL+jU4ql0DureoR/cWdenTpgE1qiXHO1yXAPwah3OVzJ79eYyfs45/f7OW2au3sm7bHgDS66Rx82kZXHxUa1KTvTPBHb7irnF44nCuktu4Yy/frMzhqc8WM2XZFto3rsXtZ3ThrB7NfAgTd1g8cXjicFWcmfHJ/PU89P58Fn67g4wmtbnu5I4M6dWCFG+BuEPgicMTh0sQefnGO7PW8rdPs5m/bjutGtRg6FGtObtnczqk1453eK4S8cThicMlmPz8oAUy6vMlTF4WzIN2RLM6nNWjOSd3Sadny3releVK5InDE4dLYGtydvP+7HW8O2stU1dswQwa1qrG8Z0a06t1fbo2r0O35nWpX7NavEN1FYgnDk8czgHBU+kTszfy2YIN/Dd7Ixu27/1uW7fmdRl+bFvO7d3Sb+118UkckgYCfwWSgWfN7PeFtl8L3ADkATuAa8xsrqQBwO+BasA+4Gdm9kl4zASgOVDwCO0ZZra+pDg8cThXvPXb9zBv7XbmrNnKuBlrmL9uO/VqpDL0qNZcckwb2jaqFe8QXZyUe+KQlAwsBAYAq4ApwDAzmxuxT10z2xa+HgJcb2YDJfUBvjWzNZJ6AOPNrGW43wTgdjOLOhN44nAuOmbG5KWbGf3Vct6fs468fOOEjMZccnQbqqcmM23FFqYu38Ke/XncNagr/do2jHfILoaKSxyxfHL8aCDbzJaEAbwCnAt8lzgKkkaoFmBh+fSI8jlADUlpZrYX51zMSOKYDo04pkMjvt22h1enrGTs5BVc9/I0IBj+vWvzOmzZuZ8LnvqKq0/owK0DOlM91bu1EkksE0dLYGXE+irgmMI7SboBuJWgW+rUIuo5H5hWKGm8ICkP+BfwoBXRbJJ0DXANQJs2bQ71MziXsJrWrc5Np2Vw/ckd+XLxJlKSRa9W9amVlsKOvbn87t15jPp8CR/P+5bbzujC6V2bUi3lwOdFdu3LZe3WPawLl16t69GpSZ04fSJXVmLZVXUBMNDMrgrXLweOMbORxex/CXCmmY2IKOsOjCO4jrE4LGtpZqsl1SFIHP8ws9ElxeJdVc7Fxn8XbeCXb85i5ebdNKxVjR/1aUmXZnWYtiKHacu3sHD9diJ/xdSslsxzI47i2I6N4he0i1o8uqpWA60j1luFZcV5BXiyYEVSK+BNYHhB0gAws9Xhz+2SxhB0iZWYOJxzsXFCRjoTbj+F/y7awKtTVvLiV8vYn2fUqZ5C3zYNOKtnM9o2qknzejWonZbCLa/O4IoXJvPM8ExO7JwOBA8szli5hWrJyWQ0re3dXpVALBPHFCBDUnuChDEUuCRyB0kZZrYoXB0ELArL6wPvAHeY2RcR+6cA9c1so6RUYDDwUQw/g3PuIJKTxMldmnBylyZs2rGXzTv30TG9dpEPF75yTX8ue24yV72YxT3ndGPZxp38+5s1rA9vCU4StGtUix90asxdg7p6EqmgYn077tnAIwS34z5vZr+RdD+QZWbjJP0VOB3YD2wBRprZHEl3A3cSJpLQGcBO4HMgNazzI+BWM8srKQ7vqnKu4sjZtY8Rz0/mm1VbqZacxMld0hncqwUpSWLBuu3MW7uND+d9y3EdGzHq8kxqpfnsD/HiDwB64nCuwtixN5eJizZybMdG1KuR+r3tb05fxe3/nEmvVvV44cqji9zHxV48rnE451yRaqelMLBHs2K3/7BPK2qkpnDj2GkMGzWJ60/pSMf02rRvXIt9eflMW76FrGVbWLt1Dzed1skfUixn3uJwzlVYny3cwPX/mMrOfUFvdJKCh73Mgmsrqcmidloqf7/yKHq0rBffYKsg76ryxOFcpbRnfx5LNuwke8MOstfvICVJZLZtQK/W9Vm7dQ/Dn/uabXtyeWZ45ne3+ebnG3tz8328rcPkicMTh3NV0tqtu7n8ucms2LSLH3RqxMotu1m5eRd7c/Opk5ZC8/rVaVG/Bucc2YLz+rQkudDdXnn5xsJvt/PNyhy+WbWV3Lx8OqTXpkN6Lbo0rUO7xonbDeaJwxOHc1VWzq593PbaN6zO2U2bhjVp26gm9WtWY/22PazZuofs9TtYunEnXZrW4ecDu9C/QyM+XbCe92avY8L89d91hdWtnkJaavIBIwb3bl2fy/q3ZfCRzRPu9mBPHJ44nEtY+fnGu7PX8ucPFrJ0406Sk0RevtGoVjXO6N6UY9o3olfr+rRrVBNJbNuzn6UbdjJl2WbGTl7B4g07qVs9hQHdmvGDTo04tmMjmterEe+PFXOeODxxOJfw9ufl8/rUVSzduJNTj2jCUe0afq/rqjAzY9KSIIF8vmgDObv2A8Fsilef0IEhvVuQWkXndPfE4YnDOXeY8vONeeu28WX2Jv41bdV3c7r/5KSODO7ZnAa1qtYMip44PHE458qQmfHxvPU8/mk2M1bmAJDRpDZHt29Ij5b1aFInjSZ1qtOsXnXS66SVWNfW3fv5y4cLad+4Fhcf1brCXEvxxOGJwzkXA2bGjJU5fLl4E1OWbSZr2RZ27M09YJ92jWpyfEZjju+Uzg86NaJO9f89CT9zVQ43jJnGys3BpKaNa6dxzYntOa93S3bty2Pzrn3s2ZdHv3YNSEsp34TiicMTh3OuHOTlG+u27WH9tj1s2L6XFZt38dXiTXy1ZBO79uWRmiyO7diYM7o1Zc/+PP7w/gIa167G45f2ZV9uPo9/ks3E7I3fq7d941o8cG4Pjs9o/N37fLZwPV9mbwqTUmNSyvhaiycOTxzOuTjal5vPtBVb+GT+esbPWcfyTbsAOPWIJvz5wl4HXB+ZvmIL01fkUK9GKg1qpbJrXx5/Gr+AZZt2cU6vFnRrXpcxk5ezcvNupOBJ+vQ6aZzXuwXHZ6TTMb0WLerVKHKE4tLwxOGJwzlXQZgZi9bvYE3Obk7MSI/qF/ye/Xk89dli/jZhMfty8+nfoSHDj23HyV3S+XzhRt6YtopPF6xnf17wO716ahLtG9fmlWv6H/IgkZ44PHE456qAdVv3sHt/Hu2LeKJ96679zFu3jSUbdrJ4ww5Wbt7F05f3Qzq0loePjuucc1VAs3rVi91Wr2Yq/Ts0on+H2E7NWzWfWnHOORcznjicc86ViicO55xzpRLTxCFpoKQFkrIl3VHE9mslzZI0Q9JESd0itt0ZHrdA0pnR1umccy62YpY4JCUDTwBnAd2AYZGJITTGzHqaWW/gD8DD4bHdgKFAd2Ag8DdJyVHW6ZxzLoZi2eI4Gsg2syVmtg94BTg3cgcz2xaxWotgVkjC/V4xs71mthTIDus7aJ3OOediK5a347YEVkasrwKOKbyTpBuAW4FqwKkRx04qdGzL8PVB6wzrvQa4BqBNmzalj94551yR4n5x3MyeMLOOwC+Au8uw3lFmlmlmmenp6WVVrXPOJbxYtjhWA60j1luFZcV5BXgyimNLUycAU6dO3Shp+cH2q+AaA98f+Syx+Tk5kJ+PA/n5+L7SnpO2RRXGMnFMATIktSf45T4UuCRyB0kZZrYoXB0EFLweB4yR9DDQAsgAJgM6WJ1FMbNK3+SQlFXUo/+JzM/Jgfx8HMjPx/eV1TmJWeIws1xJI4HxQDLwvJnNkXQ/kGVm44CRkk4H9gNbgBHhsXMkvQbMBXKBG8wsD6CoOmP1GZxzzn1fQgxyWBX4X0/f5+fkQH4+DuTn4/vK6pzE/eK4i9qoeAdQAfk5OZCfjwP5+fi+Mjkn3uJwzjlXKt7icM45VyqeOJxzzpWKJ44KKhyba7qk/4Tr7SV9HQ7u+KqkageroyqRVF/S65LmS5on6VhJDSV9KGlR+LNBvOMsL5JukTRH0mxJYyVVT7TviKTnJa2XNDuirMjvhAKPhudmpqS+8Ys8Noo5H38M/8/MlPSmpPoR24ocSDYanjgqrpuBeRHrDwF/MbNOBLcu/19cooqfvwLvm9kRQC+Cc3MH8LGZZQAfh+tVnqSWwE1Appn1ILg1fSiJ9x35O8EgqJGK+06cRfA8WAbBUERPUvX8ne+fjw+BHmZ2JLAQuBOKH0g22jfyxFEBSWpF8EDks+G6CMbxej3c5UXgvPhEV/4k1QNOBJ4DMLN9ZpZDMMDli+FuCXVOCJ7BqiEpBagJrCXBviNm9jmwuVBxcd+Jc4HRFpgE1JfUvHwiLR9FnQ8z+8DMcsPVSQSjbUDxA8lGxRNHxfQI8HMgP1xvBOREfAEiB31MBO2BDcALYffds5JqAU3NbG24zzqgadwiLEdmthr4E7CCIGFsBaaS2N+RAsV9J4oadDXRzs+PgffC14d1PjxxVDCSBgPrzWxqvGOpQFKAvsCTZtYH2EmhbikL7itPiHvLw377cwkSaguCKQkKd1EkvET6ThyMpLsIRuF4uSzq88RR8fwAGCJpGcHAj6cS9O/XD7slIMrBHauQVcAqM/s6XH+dIJF8W9DdEP5cH6f4ytvpwFIz22Bm+4E3CL43ifwdKVDcd6K0g65WGZKuAAYDl9r/Htw7rPPhiaOCMbM7zayVmbUjuHj1iZldCnwKXBDuNgJ4O04hljszWweslNQlLDqNYByzcYTjm5FY52QF0F9SzfD6V8H5SNjvSITivhPjgOHh3VX9ga0RXVpVlqSBBN3eQ8xsV8SmccBQSWnhoLEFA8lGV68/OV5xSToZuN3MBkvqQNACaQhMBy4zs73xjK88SepNcLNANWAJcCXBHz6vAW2A5cBFZlb4YmmVJOk+4GKC7ofpwFUEfdQJ8x2RNBY4mWCo8G+Be4G3KOI7ESbYxwm69HYBV5pZVjzijpVizsedQBqwKdxtkpldG+5/F8F1j1zgp2b2XuE6i30vTxzOOedKw7uqnHPOlYonDuecc6XiicM551ypeOJwzjlXKp44nHPOlYonDucOkaQ8STMiljIbZFFSu8hRTp2rSFIOvotzrhi7zax3vINwrrx5i8O5MiZpmaQ/SJolabKkTmF5O0mfhHMjfCypTVjeNJwr4ZtwOS6sKlnSM+G8Gx9IqhHuf5OkuWE9r8TpY7oE5onDuUNXo1BX1cUR27aaWU+Cp5UfCcseA14M50Z4GXg0LH8U+MzMehGMwTUnLM8AnjCz7kAOcH5YfgfQJ6zn2lh9OOeK40+OO3eIJO0ws9pFlC8DTjWzJZJSgXVm1kjSRqC5me0Py9eaWWNJG4BWkcODSGoHfBhOSISkXwCpZvagpPeBHQTDa7xlZjti/FGdO4C3OJyLDSvmdWlEjjOVx/+uSQ4CniBonUyJGBHXuXLhicO52Lg44udX4esvCUY8BrgU+G/4+mPgOvhurvl6xVUqKQlobWafAr8A6gHfa/U4F0v+l4pzh66GpBkR6++bWcEtuQ0kzSRoNQwLy24kmMXwZwQzGl4Zlt8MjJL0fwQti+sIZvYrSjLwjzC5CHg0nEbXuXLj1zicK2PhNY5MM9sY71iciwXvqnLOOVcq3uJwzjlXKt7icM45VyqeOJxzzpWKJw7nnHOl4onDOedcqXjicM45Vyr/Dyqpz48W6WcPAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the automatically saved model\n",
        "model_reloaded = load_model(checkpoint_no + '/' + model_name)\n",
        "\n",
        "# Saving the best model in the correct path and format\n",
        "root_directory = os.getcwd()\n",
        "checkpoint_dir = os.path.join(root_directory, checkpoint_no)\n",
        "model_name_temp = os.path.join(checkpoint_dir, model_name + '.h5')\n",
        "model_reloaded.save(model_name_temp)\n",
        "\n",
        "# Deletion of the automatically created folder under Model Checkpoint File.\n",
        "folder_name_temp = os.path.join(checkpoint_dir, model_name)\n",
        "shutil.rmtree(folder_name_temp, ignore_errors=True)"
      ],
      "metadata": {
        "id": "VWIRWsEVf56V"
      },
      "id": "VWIRWsEVf56V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = load_model(model_name_temp)"
      ],
      "metadata": {
        "id": "guaXpKSZt-nI"
      },
      "id": "guaXpKSZt-nI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_mae = best_model.evaluate(testX_scaled,\n",
        "                                          testY,\n",
        "                                          steps=n_test_steps)\n",
        "print()\n",
        "print('Test MAE:', test_mae)"
      ],
      "metadata": {
        "id": "5gyAvbevSxpK",
        "outputId": "6a47a808-7253-40d1-fe1c-c31116decfc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5gyAvbevSxpK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 111ms/step - loss: 0.1071 - mae: 0.2567\n",
            "\n",
            "Test MAE: 0.2566562294960022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = scaler.transform(df[features])"
      ],
      "metadata": {
        "id": "TjKzT7RnU64z"
      },
      "id": "TjKzT7RnU64z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(X)"
      ],
      "metadata": {
        "id": "T-G69u1iS2ts",
        "outputId": "fa217702-baac-49a4-8086-bc2a594dc379",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "T-G69u1iS2ts",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36/36 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_Y = pd.DataFrame(df[target])\n",
        "df_pred = pd.DataFrame(model.predict(X))\n",
        "\n",
        "df_Y.reset_index(drop=True, inplace=True)\n",
        "df_pred.reset_index(drop=True, inplace=True)\n",
        "\n",
        "df_results = pd.concat([df_Y, df_pred], axis=1)\n",
        "df_results.columns = ['Actual', 'Predicted']\n",
        "\n",
        "df_results"
      ],
      "metadata": {
        "id": "wFy8jj_9WmAy",
        "outputId": "b5462fdc-61af-4042-ed7d-7c56ff0c14c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        }
      },
      "id": "wFy8jj_9WmAy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36/36 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Actual  Predicted\n",
              "0     6.129050   6.168833\n",
              "1     6.720220   6.827619\n",
              "2     7.364547   7.180570\n",
              "3     6.591674   6.507847\n",
              "4     6.143370   5.954983\n",
              "...        ...        ...\n",
              "1127  6.907755   6.340419\n",
              "1128  6.683361   6.708959\n",
              "1129  6.444131   6.306248\n",
              "1130  6.309900   6.183661\n",
              "1131  6.746013   6.466851\n",
              "\n",
              "[1132 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48b920c5-656b-41c3-bb8f-162355dd6936\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.129050</td>\n",
              "      <td>6.168833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.720220</td>\n",
              "      <td>6.827619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.364547</td>\n",
              "      <td>7.180570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.591674</td>\n",
              "      <td>6.507847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.143370</td>\n",
              "      <td>5.954983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1127</th>\n",
              "      <td>6.907755</td>\n",
              "      <td>6.340419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1128</th>\n",
              "      <td>6.683361</td>\n",
              "      <td>6.708959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1129</th>\n",
              "      <td>6.444131</td>\n",
              "      <td>6.306248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1130</th>\n",
              "      <td>6.309900</td>\n",
              "      <td>6.183661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1131</th>\n",
              "      <td>6.746013</td>\n",
              "      <td>6.466851</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1132 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48b920c5-656b-41c3-bb8f-162355dd6936')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-48b920c5-656b-41c3-bb8f-162355dd6936 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-48b920c5-656b-41c3-bb8f-162355dd6936');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.r2_score(df[target], pred)"
      ],
      "metadata": {
        "id": "WyLZ-Ek7S4aY",
        "outputId": "67ace56d-d180-4123-9e73-9f67e6a00435",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "WyLZ-Ek7S4aY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7776325845091294"
            ]
          },
          "metadata": {},
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Mean Absolute Error:', metrics.mean_absolute_error(df[target], pred))\n",
        "print('Mean Squared Error:', metrics.mean_squared_error(df[target], pred))\n",
        "print('Root Mean Squared Error:', metrics.mean_squared_error(df[target], pred, squared=False))\n",
        "print('Mean Absolute Percentage Error:', metrics.mean_absolute_percentage_error(df[target], pred))"
      ],
      "metadata": {
        "id": "b216C2NjXVxC",
        "outputId": "39783014-2bff-42f2-a710-ce487fb7308c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "b216C2NjXVxC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 0.19128340971782043\n",
            "Mean Squared Error: 0.08156991520304348\n",
            "Root Mean Squared Error: 0.2856044733596508\n",
            "Mean Absolute Percentage Error: 0.028279678888303985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Search with KFold cross validation"
      ],
      "metadata": {
        "id": "APobIkYUness"
      },
      "id": "APobIkYUness"
    },
    {
      "cell_type": "code",
      "source": [
        "from random import shuffle\n",
        "from random import randint\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from operator import itemgetter\n",
        "import time\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import gc"
      ],
      "metadata": {
        "id": "S8t5TO2YsvGs"
      },
      "id": "S8t5TO2YsvGs",
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data/laptop_train.csv')"
      ],
      "metadata": {
        "id": "clPuxIijsnLy"
      },
      "id": "clPuxIijsnLy",
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "def create_model( nl1=1, nl2=1,  nl3=1, \n",
        "                 nn1=1000, nn2=500, nn3 = 200, lr=0.01, momentum = 0.9,  decay=0., l1=0.01, l2=0.01,\n",
        "                act = 'relu', dropout=0, input_shape=1000, output_shape=1):\n",
        "    \n",
        "    opt = keras.optimizers.SGD(lr=lr, momentum=momentum)\n",
        "    reg = keras.regularizers.l1_l2(l1=l1, l2=l2)\n",
        "                                                     \n",
        "    model = models.Sequential()\n",
        "    \n",
        "    # for the firt layer we need to specify the input dimensions\n",
        "    first=True\n",
        "    \n",
        "    for i in range(nl1):\n",
        "        if first:\n",
        "            model.add(layers.Dense(nn1, input_dim=input_shape, activation=act, kernel_regularizer=reg))\n",
        "            first=False\n",
        "        else: \n",
        "            model.add(layers.Dense(nn1, activation=act, kernel_regularizer=reg))\n",
        "        if dropout!=0:\n",
        "            model.add(layers.Dropout(dropout))\n",
        "            \n",
        "    for i in range(nl2):\n",
        "        if first:\n",
        "            model.add(layers.Dense(nn2, input_dim=input_shape, activation=act, kernel_regularizer=reg))\n",
        "            first=False\n",
        "        else: \n",
        "            model.add(layers.Dense(nn2, activation=act, kernel_regularizer=reg))\n",
        "        if dropout!=0:\n",
        "            model.add(layers.Dropout(dropout))\n",
        "            \n",
        "    for i in range(nl3):\n",
        "        if first:\n",
        "            model.add(layers.Dense(nn3, input_dim=input_shape, activation=act, kernel_regularizer=reg))\n",
        "            first=False\n",
        "        else: \n",
        "            model.add(layers.Dense(nn3, activation=act, kernel_regularizer=reg))\n",
        "        if dropout!=0:\n",
        "            model.add(layers.Dropout(dropout))\n",
        "            \n",
        "    model.add(layers.Dense(1))\n",
        "    model.compile(loss='mse', optimizer=opt, metrics=['mae'],)\n",
        "    return model"
      ],
      "metadata": {
        "id": "BFgnqj8vnobo"
      },
      "id": "BFgnqj8vnobo",
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "\n",
        "class SScaler(StandardScaler):\n",
        "  def fit_transform(self, X, y=None):\n",
        "    print(len(X))\n",
        "    return super().fit_transform(X,y)\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('sc', StandardScaler()),\n",
        "    ('kr', KerasRegressor(build_fn=create_model, epochs=100, batch_size=32, verbose=1))\n",
        "])"
      ],
      "metadata": {
        "id": "I4G5-vy_--Ns",
        "outputId": "c3675aa5-8180-4456-a620-c7f31a6bf419",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "I4G5-vy_--Ns",
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-129-e6235ae88227>:11: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  ('kr', KerasRegressor(build_fn=create_model, epochs=100, batch_size=32, verbose=1))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr=[1e-2, 1e-3, 1e-4]\n",
        "decay=[1e-6,1e-9,0]\n",
        "\n",
        "# activation\n",
        "activation=['relu', 'sigmoid']\n",
        "\n",
        "# numbers of layers\n",
        "nl1 = [0,1,2,3]\n",
        "nl2 = [0,1,2,3]\n",
        "nl3 = [0,1,2,3]\n",
        "\n",
        "# neurons in each layer\n",
        "nn1=[300,700,1400, 2100,]\n",
        "nn2=[100,400,800]\n",
        "nn3=[50,150,300]\n",
        "\n",
        "# dropout and regularisation\n",
        "dropout = [0, 0.1, 0.2, 0.3]\n",
        "l1 = [0, 0.1, 0.05, 0.01, 0.003, 0.001,0.0001]\n",
        "l2 = [0, 0.1, 0.05, 0.01, 0.003, 0.001,0.0001]\n",
        "\n",
        "# momentum\n",
        "momentum = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
        "\n",
        "# dictionary summary\n",
        "param_grid = dict(\n",
        "                    kr__nl1=nl1, kr__nl2=nl2, kr__nl3=nl3, kr__nn1=nn1, kr__nn2=nn2, kr__nn3=nn3,\n",
        "                    kr__act=activation, kr__l1=l1, kr__l2=l2, kr__lr=lr, kr__decay=decay, kr__dropout=dropout, kr__momentum=momentum,\n",
        "                    kr__input_shape=[x.shape[1]],\n",
        "                 )"
      ],
      "metadata": {
        "id": "Uk6ul1t4Dy0H"
      },
      "id": "Uk6ul1t4Dy0H",
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "\n",
        "grid = RandomizedSearchCV(estimator=pipe, cv=KFold(3), param_distributions=param_grid, \n",
        "                          verbose=20,  n_iter=1, n_jobs=1)"
      ],
      "metadata": {
        "id": "HDF-Vn-_D3Tm"
      },
      "id": "HDF-Vn-_D3Tm",
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_result = grid.fit(x.to_numpy(), y)\n",
        "grid.fit(x.to_numpy(), y)"
      ],
      "metadata": {
        "id": "1b6r85LhD7W8",
        "outputId": "a0bf0e94-7e25-46ea-d1e7-57087973b1a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "1b6r85LhD7W8",
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3; 1/1] START kr__act=sigmoid, kr__decay=0, kr__dropout=0.2, kr__input_shape=17, kr__l1=0.01, kr__l2=0.001, kr__lr=0.001, kr__momentum=0.9, kr__nl1=3, kr__nl2=2, kr__nl3=0, kr__nn1=700, kr__nn2=800, kr__nn3=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "24/24 [==============================] - 3s 47ms/step - loss: 698.8282 - mae: 2.4849\n",
            "Epoch 2/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 646.1125 - mae: 0.7985\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 596.2436 - mae: 0.5973\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 548.2866 - mae: 0.5769\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 502.3579 - mae: 0.5937\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 458.3563 - mae: 0.5673\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 1s 46ms/step - loss: 416.4521 - mae: 0.5616\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 376.5048 - mae: 0.5273\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 338.6828 - mae: 0.5459\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 1s 50ms/step - loss: 302.8717 - mae: 0.5639\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 1s 45ms/step - loss: 269.0521 - mae: 0.5668\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 1s 50ms/step - loss: 237.2476 - mae: 0.5554\n",
            "Epoch 13/100\n",
            "24/24 [==============================] - 1s 46ms/step - loss: 207.4632 - mae: 0.5487\n",
            "Epoch 14/100\n",
            "24/24 [==============================] - 1s 62ms/step - loss: 179.7171 - mae: 0.5517\n",
            "Epoch 15/100\n",
            "24/24 [==============================] - 2s 79ms/step - loss: 153.9684 - mae: 0.5451\n",
            "Epoch 16/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 130.2614 - mae: 0.5615\n",
            "Epoch 17/100\n",
            "24/24 [==============================] - 1s 51ms/step - loss: 108.5331 - mae: 0.5553\n",
            "Epoch 18/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 88.8351 - mae: 0.5460\n",
            "Epoch 19/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 71.1741 - mae: 0.5666\n",
            "Epoch 20/100\n",
            "24/24 [==============================] - 2s 64ms/step - loss: 55.4952 - mae: 0.5646\n",
            "Epoch 21/100\n",
            "24/24 [==============================] - 3s 131ms/step - loss: 41.7866 - mae: 0.5515\n",
            "Epoch 22/100\n",
            "24/24 [==============================] - 3s 108ms/step - loss: 30.1296 - mae: 0.5529\n",
            "Epoch 23/100\n",
            "24/24 [==============================] - 2s 95ms/step - loss: 20.5042 - mae: 0.5529\n",
            "Epoch 24/100\n",
            "24/24 [==============================] - 2s 66ms/step - loss: 12.9253 - mae: 0.5693\n",
            "Epoch 25/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 7.3090 - mae: 0.5516\n",
            "Epoch 26/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 3.7305 - mae: 0.5564\n",
            "Epoch 27/100\n",
            "24/24 [==============================] - 1s 51ms/step - loss: 1.8870 - mae: 0.5565\n",
            "Epoch 28/100\n",
            "24/24 [==============================] - 1s 47ms/step - loss: 1.2450 - mae: 0.5372\n",
            "Epoch 29/100\n",
            "24/24 [==============================] - 1s 45ms/step - loss: 1.1203 - mae: 0.5529\n",
            "Epoch 30/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 1.0389 - mae: 0.5486\n",
            "Epoch 31/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.9976 - mae: 0.5564\n",
            "Epoch 32/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.9830 - mae: 0.5754\n",
            "Epoch 33/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.8506 - mae: 0.5401\n",
            "Epoch 34/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.8073 - mae: 0.5421\n",
            "Epoch 35/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.7802 - mae: 0.5511\n",
            "Epoch 36/100\n",
            "24/24 [==============================] - 1s 48ms/step - loss: 0.7661 - mae: 0.5570\n",
            "Epoch 37/100\n",
            "24/24 [==============================] - 1s 44ms/step - loss: 0.7081 - mae: 0.5347\n",
            "Epoch 38/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.7403 - mae: 0.5505\n",
            "Epoch 39/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.7083 - mae: 0.5391\n",
            "Epoch 40/100\n",
            "24/24 [==============================] - 2s 84ms/step - loss: 0.7275 - mae: 0.5542\n",
            "Epoch 41/100\n",
            "24/24 [==============================] - 2s 83ms/step - loss: 0.6940 - mae: 0.5303\n",
            "Epoch 42/100\n",
            "24/24 [==============================] - 2s 86ms/step - loss: 0.7403 - mae: 0.5548\n",
            "Epoch 43/100\n",
            "24/24 [==============================] - 2s 82ms/step - loss: 0.7054 - mae: 0.5404\n",
            "Epoch 44/100\n",
            "24/24 [==============================] - 1s 61ms/step - loss: 0.7583 - mae: 0.5573\n",
            "Epoch 45/100\n",
            "24/24 [==============================] - 1s 47ms/step - loss: 0.7217 - mae: 0.5490\n",
            "Epoch 46/100\n",
            "24/24 [==============================] - 1s 44ms/step - loss: 0.7646 - mae: 0.5642\n",
            "Epoch 47/100\n",
            "24/24 [==============================] - 1s 46ms/step - loss: 0.8286 - mae: 0.5834\n",
            "Epoch 48/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 0.7577 - mae: 0.5558\n",
            "Epoch 49/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.7130 - mae: 0.5486\n",
            "Epoch 50/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 0.7042 - mae: 0.5328\n",
            "Epoch 51/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.6947 - mae: 0.5340\n",
            "Epoch 52/100\n",
            "24/24 [==============================] - 1s 45ms/step - loss: 0.7169 - mae: 0.5463\n",
            "Epoch 53/100\n",
            "24/24 [==============================] - 1s 44ms/step - loss: 0.7247 - mae: 0.5502\n",
            "Epoch 54/100\n",
            "24/24 [==============================] - 1s 44ms/step - loss: 0.7470 - mae: 0.5567\n",
            "Epoch 55/100\n",
            "24/24 [==============================] - 1s 50ms/step - loss: 0.7423 - mae: 0.5487\n",
            "Epoch 56/100\n",
            "24/24 [==============================] - 1s 44ms/step - loss: 0.7328 - mae: 0.5454\n",
            "Epoch 57/100\n",
            "24/24 [==============================] - 1s 49ms/step - loss: 0.7415 - mae: 0.5512\n",
            "Epoch 58/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 0.7162 - mae: 0.5422\n",
            "Epoch 59/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.7193 - mae: 0.5460\n",
            "Epoch 60/100\n",
            "24/24 [==============================] - 1s 45ms/step - loss: 0.7001 - mae: 0.5324\n",
            "Epoch 61/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.7041 - mae: 0.5419\n",
            "Epoch 62/100\n",
            "24/24 [==============================] - 1s 48ms/step - loss: 0.7126 - mae: 0.5442\n",
            "Epoch 63/100\n",
            "24/24 [==============================] - 1s 47ms/step - loss: 0.7194 - mae: 0.5418\n",
            "Epoch 64/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.7134 - mae: 0.5411\n",
            "Epoch 65/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.7108 - mae: 0.5387\n",
            "Epoch 66/100\n",
            "24/24 [==============================] - 1s 51ms/step - loss: 0.6948 - mae: 0.5297\n",
            "Epoch 67/100\n",
            "24/24 [==============================] - 1s 48ms/step - loss: 0.7120 - mae: 0.5389\n",
            "Epoch 68/100\n",
            "24/24 [==============================] - 1s 49ms/step - loss: 0.7456 - mae: 0.5649\n",
            "Epoch 69/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.7321 - mae: 0.5505\n",
            "Epoch 70/100\n",
            "24/24 [==============================] - 1s 45ms/step - loss: 0.7108 - mae: 0.5347\n",
            "Epoch 71/100\n",
            "24/24 [==============================] - 1s 44ms/step - loss: 0.6952 - mae: 0.5368\n",
            "Epoch 72/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.6794 - mae: 0.5248\n",
            "Epoch 73/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.6962 - mae: 0.5337\n",
            "Epoch 74/100\n",
            "24/24 [==============================] - 1s 48ms/step - loss: 0.7494 - mae: 0.5644\n",
            "Epoch 75/100\n",
            "24/24 [==============================] - 1s 45ms/step - loss: 0.7347 - mae: 0.5500\n",
            "Epoch 76/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 0.7048 - mae: 0.5396\n",
            "Epoch 77/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 0.7032 - mae: 0.5409\n",
            "Epoch 78/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 0.7185 - mae: 0.5329\n",
            "Epoch 79/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.7067 - mae: 0.5390\n",
            "Epoch 80/100\n",
            "24/24 [==============================] - 1s 44ms/step - loss: 0.7209 - mae: 0.5383\n",
            "Epoch 81/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 0.7200 - mae: 0.5423\n",
            "Epoch 82/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.6868 - mae: 0.5217\n",
            "Epoch 83/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.6991 - mae: 0.5291\n",
            "Epoch 84/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 0.7068 - mae: 0.5357\n",
            "Epoch 85/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 0.7078 - mae: 0.5425\n",
            "Epoch 86/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.7387 - mae: 0.5520\n",
            "Epoch 87/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.7411 - mae: 0.5538\n",
            "Epoch 88/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 0.7207 - mae: 0.5490\n",
            "Epoch 89/100\n",
            "24/24 [==============================] - 1s 50ms/step - loss: 0.7245 - mae: 0.5512\n",
            "Epoch 90/100\n",
            "24/24 [==============================] - 1s 44ms/step - loss: 0.7570 - mae: 0.5556\n",
            "Epoch 91/100\n",
            "24/24 [==============================] - 1s 45ms/step - loss: 0.8047 - mae: 0.5718\n",
            "Epoch 92/100\n",
            "24/24 [==============================] - 1s 44ms/step - loss: 0.7352 - mae: 0.5557\n",
            "Epoch 93/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.7603 - mae: 0.5552\n",
            "Epoch 94/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 0.7146 - mae: 0.5337\n",
            "Epoch 95/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.7111 - mae: 0.5382\n",
            "Epoch 96/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 0.7356 - mae: 0.5470\n",
            "Epoch 97/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 0.7261 - mae: 0.5464\n",
            "Epoch 98/100\n",
            "24/24 [==============================] - 3s 110ms/step - loss: 0.6999 - mae: 0.5332\n",
            "Epoch 99/100\n",
            "24/24 [==============================] - 1s 44ms/step - loss: 0.7020 - mae: 0.5402\n",
            "Epoch 100/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 0.7256 - mae: 0.5455\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.6578 - mae: 0.5030\n",
            "[CV 1/3; 1/1] END kr__act=sigmoid, kr__decay=0, kr__dropout=0.2, kr__input_shape=17, kr__l1=0.01, kr__l2=0.001, kr__lr=0.001, kr__momentum=0.9, kr__nl1=3, kr__nl2=2, kr__nl3=0, kr__nn1=700, kr__nn2=800, kr__nn3=300;, score=-0.658 total time= 2.4min\n",
            "[CV 2/3; 1/1] START kr__act=sigmoid, kr__decay=0, kr__dropout=0.2, kr__input_shape=17, kr__l1=0.01, kr__l2=0.001, kr__lr=0.001, kr__momentum=0.9, kr__nl1=3, kr__nl2=2, kr__nl3=0, kr__nn1=700, kr__nn2=800, kr__nn3=300\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 2s 46ms/step - loss: 699.3306 - mae: 2.6449\n",
            "Epoch 2/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 645.7068 - mae: 0.9043\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 595.5365 - mae: 0.5807\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 547.5343 - mae: 0.5510\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 501.5860 - mae: 0.5560\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 457.6349 - mae: 0.5444\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 415.7336 - mae: 0.5507\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 1s 48ms/step - loss: 375.8358 - mae: 0.5361\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 2s 65ms/step - loss: 337.9756 - mae: 0.5373\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 2s 95ms/step - loss: 302.1795 - mae: 0.5666\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 2s 67ms/step - loss: 268.3511 - mae: 0.5485\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 1s 47ms/step - loss: 236.6236 - mae: 0.5590\n",
            "Epoch 13/100\n",
            "24/24 [==============================] - 1s 47ms/step - loss: 206.8303 - mae: 0.5396\n",
            "Epoch 14/100\n",
            "24/24 [==============================] - 1s 48ms/step - loss: 179.1124 - mae: 0.5378\n",
            "Epoch 15/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 153.3993 - mae: 0.5261\n",
            "Epoch 16/100\n",
            "24/24 [==============================] - 1s 50ms/step - loss: 129.7748 - mae: 0.5427\n",
            "Epoch 17/100\n",
            "24/24 [==============================] - 1s 45ms/step - loss: 108.0964 - mae: 0.5291\n",
            "Epoch 18/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 88.4762 - mae: 0.5377\n",
            "Epoch 19/100\n",
            "24/24 [==============================] - 1s 45ms/step - loss: 70.8534 - mae: 0.5411\n",
            "Epoch 20/100\n",
            "24/24 [==============================] - 1s 47ms/step - loss: 55.2275 - mae: 0.5307\n",
            "Epoch 21/100\n",
            "24/24 [==============================] - 1s 48ms/step - loss: 41.6288 - mae: 0.5320\n",
            "Epoch 22/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 30.0062 - mae: 0.5238\n",
            "Epoch 23/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 20.4319 - mae: 0.5324\n",
            "Epoch 24/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 12.8345 - mae: 0.5276\n",
            "Epoch 25/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 7.2763 - mae: 0.5300\n",
            "Epoch 26/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 3.6840 - mae: 0.5339\n",
            "Epoch 27/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 1.8361 - mae: 0.5332\n",
            "Epoch 28/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 1.2174 - mae: 0.5358\n",
            "Epoch 29/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 1.1055 - mae: 0.5518\n",
            "Epoch 30/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 0.9845 - mae: 0.5146\n",
            "Epoch 31/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.9149 - mae: 0.5266\n",
            "Epoch 32/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.9003 - mae: 0.5432\n",
            "Epoch 33/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.8086 - mae: 0.5204\n",
            "Epoch 34/100\n",
            "24/24 [==============================] - 1s 48ms/step - loss: 0.7780 - mae: 0.5301\n",
            "Epoch 35/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 0.7599 - mae: 0.5321\n",
            "Epoch 36/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.7060 - mae: 0.5156\n",
            "Epoch 37/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.7011 - mae: 0.5227\n",
            "Epoch 38/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.7307 - mae: 0.5403\n",
            "Epoch 39/100\n",
            "24/24 [==============================] - 1s 50ms/step - loss: 0.7558 - mae: 0.5524\n",
            "Epoch 40/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.7444 - mae: 0.5422\n",
            "Epoch 41/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.6969 - mae: 0.5235\n",
            "Epoch 42/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.7332 - mae: 0.5380\n",
            "Epoch 43/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.7081 - mae: 0.5299\n",
            "Epoch 44/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.7572 - mae: 0.5480\n",
            "Epoch 45/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 0.6981 - mae: 0.5234\n",
            "Epoch 46/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 0.6826 - mae: 0.5197\n",
            "Epoch 47/100\n",
            "24/24 [==============================] - 1s 59ms/step - loss: 0.6872 - mae: 0.5200\n",
            "Epoch 48/100\n",
            "24/24 [==============================] - 1s 58ms/step - loss: 0.6884 - mae: 0.5250\n",
            "Epoch 49/100\n",
            "24/24 [==============================] - 1s 58ms/step - loss: 0.7208 - mae: 0.5373\n",
            "Epoch 50/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.6880 - mae: 0.5188\n",
            "Epoch 51/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 0.6994 - mae: 0.5352\n",
            "Epoch 52/100\n",
            "24/24 [==============================] - 1s 48ms/step - loss: 0.7080 - mae: 0.5328\n",
            "Epoch 53/100\n",
            "24/24 [==============================] - 1s 47ms/step - loss: 0.6908 - mae: 0.5262\n",
            "Epoch 54/100\n",
            "24/24 [==============================] - 1s 48ms/step - loss: 0.6949 - mae: 0.5211\n",
            "Epoch 55/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.6733 - mae: 0.5153\n",
            "Epoch 56/100\n",
            "24/24 [==============================] - 1s 58ms/step - loss: 0.6833 - mae: 0.5212\n",
            "Epoch 57/100\n",
            "24/24 [==============================] - 1s 49ms/step - loss: 0.6667 - mae: 0.5088\n",
            "Epoch 58/100\n",
            "24/24 [==============================] - 1s 58ms/step - loss: 0.6932 - mae: 0.5249\n",
            "Epoch 59/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.6658 - mae: 0.5093\n",
            "Epoch 60/100\n",
            "24/24 [==============================] - 1s 50ms/step - loss: 0.6752 - mae: 0.5131\n",
            "Epoch 61/100\n",
            "24/24 [==============================] - 1s 48ms/step - loss: 0.6663 - mae: 0.5150\n",
            "Epoch 62/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.6894 - mae: 0.5295\n",
            "Epoch 63/100\n",
            "24/24 [==============================] - 1s 58ms/step - loss: 0.7201 - mae: 0.5346\n",
            "Epoch 64/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.7284 - mae: 0.5486\n",
            "Epoch 65/100\n",
            "24/24 [==============================] - 1s 46ms/step - loss: 0.7479 - mae: 0.5468\n",
            "Epoch 66/100\n",
            "24/24 [==============================] - 1s 47ms/step - loss: 0.6754 - mae: 0.5144\n",
            "Epoch 67/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.6650 - mae: 0.5076\n",
            "Epoch 68/100\n",
            "24/24 [==============================] - 3s 110ms/step - loss: 0.6898 - mae: 0.5230\n",
            "Epoch 69/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 0.6889 - mae: 0.5246\n",
            "Epoch 70/100\n",
            "24/24 [==============================] - 1s 58ms/step - loss: 0.6763 - mae: 0.5180\n",
            "Epoch 71/100\n",
            "24/24 [==============================] - 1s 58ms/step - loss: 0.6875 - mae: 0.5233\n",
            "Epoch 72/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.6864 - mae: 0.5211\n",
            "Epoch 73/100\n",
            "24/24 [==============================] - 1s 58ms/step - loss: 0.6731 - mae: 0.5066\n",
            "Epoch 74/100\n",
            "24/24 [==============================] - 1s 58ms/step - loss: 0.6762 - mae: 0.5152\n",
            "Epoch 75/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 0.6698 - mae: 0.5128\n",
            "Epoch 76/100\n",
            "24/24 [==============================] - 1s 58ms/step - loss: 0.7040 - mae: 0.5231\n",
            "Epoch 77/100\n",
            "24/24 [==============================] - 1s 58ms/step - loss: 0.7467 - mae: 0.5429\n",
            "Epoch 78/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.6744 - mae: 0.5122\n",
            "Epoch 79/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.7098 - mae: 0.5324\n",
            "Epoch 80/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 0.7141 - mae: 0.5365\n",
            "Epoch 81/100\n",
            "24/24 [==============================] - 1s 49ms/step - loss: 0.7009 - mae: 0.5255\n",
            "Epoch 82/100\n",
            "24/24 [==============================] - 1s 58ms/step - loss: 0.7126 - mae: 0.5396\n",
            "Epoch 83/100\n",
            "24/24 [==============================] - 1s 58ms/step - loss: 0.7236 - mae: 0.5392\n",
            "Epoch 84/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.6718 - mae: 0.5118\n",
            "Epoch 85/100\n",
            "24/24 [==============================] - 1s 58ms/step - loss: 0.6991 - mae: 0.5325\n",
            "Epoch 86/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 0.6817 - mae: 0.5162\n",
            "Epoch 87/100\n",
            "24/24 [==============================] - 1s 48ms/step - loss: 0.6808 - mae: 0.5189\n",
            "Epoch 88/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.6751 - mae: 0.5186\n",
            "Epoch 89/100\n",
            "24/24 [==============================] - 1s 58ms/step - loss: 0.7321 - mae: 0.5433\n",
            "Epoch 90/100\n",
            "24/24 [==============================] - 1s 48ms/step - loss: 0.6808 - mae: 0.5128\n",
            "Epoch 91/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.6752 - mae: 0.5147\n",
            "Epoch 92/100\n",
            "24/24 [==============================] - 1s 58ms/step - loss: 0.7016 - mae: 0.5317\n",
            "Epoch 93/100\n",
            "24/24 [==============================] - 1s 59ms/step - loss: 0.6828 - mae: 0.5161\n",
            "Epoch 94/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.6825 - mae: 0.5220\n",
            "Epoch 95/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.6661 - mae: 0.5135\n",
            "Epoch 96/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.7102 - mae: 0.5274\n",
            "Epoch 97/100\n",
            "24/24 [==============================] - 2s 64ms/step - loss: 0.6864 - mae: 0.5269\n",
            "Epoch 98/100\n",
            "24/24 [==============================] - 2s 102ms/step - loss: 0.6725 - mae: 0.5149\n",
            "Epoch 99/100\n",
            "24/24 [==============================] - 2s 96ms/step - loss: 0.6790 - mae: 0.5188\n",
            "Epoch 100/100\n",
            "24/24 [==============================] - 2s 96ms/step - loss: 0.7098 - mae: 0.5373\n",
            "12/12 [==============================] - 1s 28ms/step - loss: 0.8674 - mae: 0.6121\n",
            "[CV 2/3; 1/1] END kr__act=sigmoid, kr__decay=0, kr__dropout=0.2, kr__input_shape=17, kr__l1=0.01, kr__l2=0.001, kr__lr=0.001, kr__momentum=0.9, kr__nl1=3, kr__nl2=2, kr__nl3=0, kr__nn1=700, kr__nn2=800, kr__nn3=300;, score=-0.867 total time= 2.3min\n",
            "[CV 3/3; 1/1] START kr__act=sigmoid, kr__decay=0, kr__dropout=0.2, kr__input_shape=17, kr__l1=0.01, kr__l2=0.001, kr__lr=0.001, kr__momentum=0.9, kr__nl1=3, kr__nl2=2, kr__nl3=0, kr__nn1=700, kr__nn2=800, kr__nn3=300\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 2s 57ms/step - loss: 697.8854 - mae: 2.4480\n",
            "Epoch 2/100\n",
            "24/24 [==============================] - 1s 49ms/step - loss: 645.6111 - mae: 0.9183\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 1s 45ms/step - loss: 595.4508 - mae: 0.5927\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 1s 48ms/step - loss: 547.4510 - mae: 0.5844\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 501.4790 - mae: 0.5719\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 457.5534 - mae: 0.5788\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 415.6223 - mae: 0.5617\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 375.7781 - mae: 0.5781\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 1s 50ms/step - loss: 337.9022 - mae: 0.5503\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 1s 46ms/step - loss: 302.0940 - mae: 0.5595\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 268.2909 - mae: 0.5515\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 1s 58ms/step - loss: 236.5397 - mae: 0.5443\n",
            "Epoch 13/100\n",
            "24/24 [==============================] - 1s 58ms/step - loss: 206.8017 - mae: 0.5433\n",
            "Epoch 14/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 179.1063 - mae: 0.5631\n",
            "Epoch 15/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 153.4071 - mae: 0.5548\n",
            "Epoch 16/100\n",
            "24/24 [==============================] - 1s 48ms/step - loss: 129.7385 - mae: 0.5607\n",
            "Epoch 17/100\n",
            "24/24 [==============================] - 1s 58ms/step - loss: 108.1028 - mae: 0.5572\n",
            "Epoch 18/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 88.4804 - mae: 0.5630\n",
            "Epoch 19/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 70.8585 - mae: 0.5613\n",
            "Epoch 20/100\n",
            "24/24 [==============================] - 1s 59ms/step - loss: 55.2361 - mae: 0.5508\n",
            "Epoch 21/100\n",
            "24/24 [==============================] - 1s 58ms/step - loss: 41.6967 - mae: 0.5756\n",
            "Epoch 22/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 30.0710 - mae: 0.5528\n",
            "Epoch 23/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 20.4871 - mae: 0.5575\n",
            "Epoch 24/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 12.9640 - mae: 0.5864\n",
            "Epoch 25/100\n",
            "24/24 [==============================] - 2s 100ms/step - loss: 7.3284 - mae: 0.5499\n",
            "Epoch 26/100\n",
            "24/24 [==============================] - 2s 66ms/step - loss: 3.7096 - mae: 0.5468\n",
            "Epoch 27/100\n",
            "24/24 [==============================] - 1s 49ms/step - loss: 1.8866 - mae: 0.5617\n",
            "Epoch 28/100\n",
            "24/24 [==============================] - 1s 59ms/step - loss: 1.2619 - mae: 0.5517\n",
            "Epoch 29/100\n",
            "24/24 [==============================] - 1s 48ms/step - loss: 1.1781 - mae: 0.5753\n",
            "Epoch 30/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 1.0509 - mae: 0.5481\n",
            "Epoch 31/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 0.9747 - mae: 0.5532\n",
            "Epoch 32/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.9704 - mae: 0.5791\n",
            "Epoch 33/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.9105 - mae: 0.5626\n",
            "Epoch 34/100\n",
            "24/24 [==============================] - 1s 46ms/step - loss: 0.8662 - mae: 0.5680\n",
            "Epoch 35/100\n",
            "24/24 [==============================] - 1s 47ms/step - loss: 0.8100 - mae: 0.5490\n",
            "Epoch 36/100\n",
            "24/24 [==============================] - 1s 45ms/step - loss: 0.8020 - mae: 0.5692\n",
            "Epoch 37/100\n",
            "24/24 [==============================] - 1s 48ms/step - loss: 0.7497 - mae: 0.5567\n",
            "Epoch 38/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 0.7357 - mae: 0.5502\n",
            "Epoch 39/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 0.7280 - mae: 0.5493\n",
            "Epoch 40/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.7660 - mae: 0.5654\n",
            "Epoch 41/100\n",
            "24/24 [==============================] - 1s 50ms/step - loss: 0.7003 - mae: 0.5324\n",
            "Epoch 42/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.7296 - mae: 0.5476\n",
            "Epoch 43/100\n",
            "24/24 [==============================] - 1s 58ms/step - loss: 0.7424 - mae: 0.5489\n",
            "Epoch 44/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 0.7168 - mae: 0.5396\n",
            "Epoch 45/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.7463 - mae: 0.5472\n",
            "Epoch 46/100\n",
            "24/24 [==============================] - 1s 45ms/step - loss: 0.7203 - mae: 0.5353\n",
            "Epoch 47/100\n",
            "24/24 [==============================] - 1s 44ms/step - loss: 0.7214 - mae: 0.5467\n",
            "Epoch 48/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.7335 - mae: 0.5499\n",
            "Epoch 49/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 0.7504 - mae: 0.5609\n",
            "Epoch 50/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.7097 - mae: 0.5402\n",
            "Epoch 51/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 0.7049 - mae: 0.5390\n",
            "Epoch 52/100\n",
            "24/24 [==============================] - 1s 48ms/step - loss: 0.7010 - mae: 0.5446\n",
            "Epoch 53/100\n",
            "24/24 [==============================] - 1s 58ms/step - loss: 0.7138 - mae: 0.5392\n",
            "Epoch 54/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.7095 - mae: 0.5386\n",
            "Epoch 55/100\n",
            "24/24 [==============================] - 1s 58ms/step - loss: 0.7446 - mae: 0.5625\n",
            "Epoch 56/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 0.7548 - mae: 0.5579\n",
            "Epoch 57/100\n",
            "24/24 [==============================] - 1s 58ms/step - loss: 0.7158 - mae: 0.5370\n",
            "Epoch 58/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.7298 - mae: 0.5536\n",
            "Epoch 59/100\n",
            "24/24 [==============================] - 1s 51ms/step - loss: 0.7324 - mae: 0.5556\n",
            "Epoch 60/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 0.7650 - mae: 0.5746\n",
            "Epoch 61/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.7279 - mae: 0.5489\n",
            "Epoch 62/100\n",
            "24/24 [==============================] - 1s 44ms/step - loss: 0.7764 - mae: 0.5707\n",
            "Epoch 63/100\n",
            "24/24 [==============================] - 1s 49ms/step - loss: 0.7453 - mae: 0.5543\n",
            "Epoch 64/100\n",
            "24/24 [==============================] - 1s 50ms/step - loss: 0.7318 - mae: 0.5511\n",
            "Epoch 65/100\n",
            "24/24 [==============================] - 1s 45ms/step - loss: 0.7135 - mae: 0.5482\n",
            "Epoch 66/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.7176 - mae: 0.5515\n",
            "Epoch 67/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.7552 - mae: 0.5555\n",
            "Epoch 68/100\n",
            "24/24 [==============================] - 1s 49ms/step - loss: 0.7466 - mae: 0.5558\n",
            "Epoch 69/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.7446 - mae: 0.5602\n",
            "Epoch 70/100\n",
            "24/24 [==============================] - 1s 58ms/step - loss: 0.7368 - mae: 0.5546\n",
            "Epoch 71/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.7656 - mae: 0.5646\n",
            "Epoch 72/100\n",
            "24/24 [==============================] - 1s 50ms/step - loss: 0.7075 - mae: 0.5407\n",
            "Epoch 73/100\n",
            "24/24 [==============================] - 1s 44ms/step - loss: 0.7073 - mae: 0.5376\n",
            "Epoch 74/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.7327 - mae: 0.5577\n",
            "Epoch 75/100\n",
            "24/24 [==============================] - 1s 58ms/step - loss: 0.7031 - mae: 0.5368\n",
            "Epoch 76/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 0.7041 - mae: 0.5422\n",
            "Epoch 77/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 0.7025 - mae: 0.5354\n",
            "Epoch 78/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.7257 - mae: 0.5528\n",
            "Epoch 79/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 0.7026 - mae: 0.5375\n",
            "Epoch 80/100\n",
            "24/24 [==============================] - 1s 58ms/step - loss: 0.6936 - mae: 0.5358\n",
            "Epoch 81/100\n",
            "24/24 [==============================] - 1s 58ms/step - loss: 0.7260 - mae: 0.5426\n",
            "Epoch 82/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 0.7098 - mae: 0.5433\n",
            "Epoch 83/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 0.7258 - mae: 0.5492\n",
            "Epoch 84/100\n",
            "24/24 [==============================] - 1s 58ms/step - loss: 0.7117 - mae: 0.5413\n",
            "Epoch 85/100\n",
            "24/24 [==============================] - 1s 51ms/step - loss: 0.7007 - mae: 0.5332\n",
            "Epoch 86/100\n",
            "24/24 [==============================] - 1s 45ms/step - loss: 0.6984 - mae: 0.5367\n",
            "Epoch 87/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.7282 - mae: 0.5383\n",
            "Epoch 88/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.7208 - mae: 0.5476\n",
            "Epoch 89/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.7173 - mae: 0.5488\n",
            "Epoch 90/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.7174 - mae: 0.5527\n",
            "Epoch 91/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.7234 - mae: 0.5491\n",
            "Epoch 92/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 0.7370 - mae: 0.5534\n",
            "Epoch 93/100\n",
            "24/24 [==============================] - 1s 57ms/step - loss: 0.7909 - mae: 0.5838\n",
            "Epoch 94/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 0.6969 - mae: 0.5315\n",
            "Epoch 95/100\n",
            "24/24 [==============================] - 1s 58ms/step - loss: 0.7093 - mae: 0.5427\n",
            "Epoch 96/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 0.7417 - mae: 0.5576\n",
            "Epoch 97/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 0.7244 - mae: 0.5514\n",
            "Epoch 98/100\n",
            "24/24 [==============================] - 1s 59ms/step - loss: 0.7154 - mae: 0.5485\n",
            "Epoch 99/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 0.7040 - mae: 0.5384\n",
            "Epoch 100/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.6849 - mae: 0.5284\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.6331 - mae: 0.4937\n",
            "[CV 3/3; 1/1] END kr__act=sigmoid, kr__decay=0, kr__dropout=0.2, kr__input_shape=17, kr__l1=0.01, kr__l2=0.001, kr__lr=0.001, kr__momentum=0.9, kr__nl1=3, kr__nl2=2, kr__nl3=0, kr__nn1=700, kr__nn2=800, kr__nn3=300;, score=-0.633 total time= 2.2min\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36/36 [==============================] - 3s 51ms/step - loss: 686.6722 - mae: 2.1813\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 2s 55ms/step - loss: 608.4281 - mae: 0.6109\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 2s 57ms/step - loss: 536.4796 - mae: 0.5850\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 2s 55ms/step - loss: 469.0023 - mae: 0.5558\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 2s 56ms/step - loss: 406.1006 - mae: 0.5414\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 2s 56ms/step - loss: 347.8023 - mae: 0.5480\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 2s 56ms/step - loss: 294.0536 - mae: 0.5420\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 2s 58ms/step - loss: 244.8837 - mae: 0.5476\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 2s 56ms/step - loss: 200.2544 - mae: 0.5461\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 160.1707 - mae: 0.5539\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 2s 50ms/step - loss: 124.5915 - mae: 0.5563\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 93.5832 - mae: 0.5597\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 67.0944 - mae: 0.5628\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 45.1078 - mae: 0.5529\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 27.6318 - mae: 0.5557\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 14.7192 - mae: 0.5393\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 6.3418 - mae: 0.5449\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 2s 50ms/step - loss: 2.2428 - mae: 0.5446\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 1.1785 - mae: 0.5402\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 1.0092 - mae: 0.5379\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 2s 47ms/step - loss: 0.9259 - mae: 0.5457\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 2s 57ms/step - loss: 0.8605 - mae: 0.5474\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 2s 56ms/step - loss: 0.7833 - mae: 0.5411\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 2s 56ms/step - loss: 0.7395 - mae: 0.5367\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 2s 56ms/step - loss: 0.7163 - mae: 0.5379\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 2s 56ms/step - loss: 0.7058 - mae: 0.5385\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 0.7564 - mae: 0.5580\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 2s 49ms/step - loss: 0.6990 - mae: 0.5322\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 2s 56ms/step - loss: 0.7233 - mae: 0.5482\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 2s 57ms/step - loss: 0.7011 - mae: 0.5349\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 2s 56ms/step - loss: 0.6893 - mae: 0.5306\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.7224 - mae: 0.5408\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.6869 - mae: 0.5255\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.7100 - mae: 0.5426\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 2s 56ms/step - loss: 0.6958 - mae: 0.5275\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 2s 49ms/step - loss: 0.7436 - mae: 0.5493\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 2s 56ms/step - loss: 0.7119 - mae: 0.5407\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 2s 56ms/step - loss: 0.7076 - mae: 0.5337\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 2s 57ms/step - loss: 0.7122 - mae: 0.5364\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 2s 57ms/step - loss: 0.7120 - mae: 0.5357\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 2s 56ms/step - loss: 0.7080 - mae: 0.5313\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 2s 57ms/step - loss: 0.7162 - mae: 0.5372\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 2s 56ms/step - loss: 0.7046 - mae: 0.5364\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 2s 57ms/step - loss: 0.7227 - mae: 0.5441\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 2s 58ms/step - loss: 0.6986 - mae: 0.5304\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.7086 - mae: 0.5367\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.7184 - mae: 0.5421\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 2s 57ms/step - loss: 0.7087 - mae: 0.5412\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.7054 - mae: 0.5371\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 2s 55ms/step - loss: 0.6955 - mae: 0.5344\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 2s 58ms/step - loss: 0.7056 - mae: 0.5387\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 2s 57ms/step - loss: 0.7263 - mae: 0.5551\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 2s 57ms/step - loss: 0.7242 - mae: 0.5363\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 2s 56ms/step - loss: 0.7115 - mae: 0.5382\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 2s 57ms/step - loss: 0.6966 - mae: 0.5347\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 2s 57ms/step - loss: 0.6981 - mae: 0.5323\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 2s 58ms/step - loss: 0.7341 - mae: 0.5491\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 2s 56ms/step - loss: 0.7098 - mae: 0.5383\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 2s 57ms/step - loss: 0.6830 - mae: 0.5272\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 2s 58ms/step - loss: 0.6982 - mae: 0.5308\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 2s 57ms/step - loss: 0.6978 - mae: 0.5334\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 2s 57ms/step - loss: 0.6943 - mae: 0.5293\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 2s 57ms/step - loss: 0.6912 - mae: 0.5337\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 2s 58ms/step - loss: 0.7134 - mae: 0.5420\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 2s 58ms/step - loss: 0.7056 - mae: 0.5364\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 2s 58ms/step - loss: 0.6974 - mae: 0.5285\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 2s 58ms/step - loss: 0.6950 - mae: 0.5359\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 2s 58ms/step - loss: 0.7412 - mae: 0.5561\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 0.7256 - mae: 0.5483\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.7988 - mae: 0.5741\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 2s 58ms/step - loss: 0.6986 - mae: 0.5280\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 2s 63ms/step - loss: 0.6951 - mae: 0.5294\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 2s 57ms/step - loss: 0.6934 - mae: 0.5339\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 2s 58ms/step - loss: 0.6831 - mae: 0.5248\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 2s 58ms/step - loss: 0.7215 - mae: 0.5477\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 2s 58ms/step - loss: 0.7077 - mae: 0.5366\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 2s 56ms/step - loss: 0.6921 - mae: 0.5367\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 2s 57ms/step - loss: 0.7047 - mae: 0.5338\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 2s 57ms/step - loss: 0.7111 - mae: 0.5375\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 2s 58ms/step - loss: 0.7122 - mae: 0.5379\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 2s 58ms/step - loss: 0.7102 - mae: 0.5351\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 2s 58ms/step - loss: 0.7251 - mae: 0.5472\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 2s 57ms/step - loss: 0.7256 - mae: 0.5520\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 2s 47ms/step - loss: 0.6964 - mae: 0.5319\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 0.6969 - mae: 0.5332\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 0.6982 - mae: 0.5300\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 2s 55ms/step - loss: 0.7176 - mae: 0.5403\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 2s 50ms/step - loss: 0.6850 - mae: 0.5287\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 2s 57ms/step - loss: 0.6879 - mae: 0.5298\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 2s 58ms/step - loss: 0.6995 - mae: 0.5332\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 2s 58ms/step - loss: 0.7027 - mae: 0.5319\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 2s 57ms/step - loss: 0.7271 - mae: 0.5530\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 2s 57ms/step - loss: 0.7028 - mae: 0.5344\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 2s 58ms/step - loss: 0.6890 - mae: 0.5290\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 2s 57ms/step - loss: 0.6839 - mae: 0.5253\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 2s 58ms/step - loss: 0.6840 - mae: 0.5333\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 2s 58ms/step - loss: 0.7265 - mae: 0.5457\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 2s 60ms/step - loss: 0.7404 - mae: 0.5592\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 2s 58ms/step - loss: 0.7067 - mae: 0.5315\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 2s 57ms/step - loss: 0.6888 - mae: 0.5274\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3; 1/1] START kr__act=sigmoid, kr__decay=1e-09, kr__dropout=0.1, kr__input_shape=17, kr__l1=0.01, kr__l2=0.003, kr__lr=0.01, kr__momentum=0.3, kr__nl1=0, kr__nl2=3, kr__nl3=2, kr__nn1=300, kr__nn2=800, kr__nn3=150\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 2s 33ms/step - loss: 447.9688 - mae: 0.9295\n",
            "Epoch 2/100\n",
            "24/24 [==============================] - 1s 32ms/step - loss: 397.4748 - mae: 0.5716\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 351.9389 - mae: 0.5699\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 309.2393 - mae: 0.5666\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 269.4387 - mae: 0.5881\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 1s 41ms/step - loss: 232.4786 - mae: 0.5776\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 1s 34ms/step - loss: 198.3386 - mae: 0.5602\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 167.0524 - mae: 0.5582\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 138.6360 - mae: 0.5587\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 1s 41ms/step - loss: 113.0108 - mae: 0.5675\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 1s 41ms/step - loss: 90.2052 - mae: 0.5579\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 1s 37ms/step - loss: 70.2383 - mae: 0.5625\n",
            "Epoch 13/100\n",
            "24/24 [==============================] - 1s 32ms/step - loss: 53.0996 - mae: 0.5733\n",
            "Epoch 14/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 38.7294 - mae: 0.5633\n",
            "Epoch 15/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 27.1768 - mae: 0.5525\n",
            "Epoch 16/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 18.4270 - mae: 0.5588\n",
            "Epoch 17/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 12.4663 - mae: 0.5439\n",
            "Epoch 18/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 9.3132 - mae: 0.5647\n",
            "Epoch 19/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 7.7661 - mae: 0.5460\n",
            "Epoch 20/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 6.5435 - mae: 0.5457\n",
            "Epoch 21/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 5.5582 - mae: 0.5469\n",
            "Epoch 22/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 4.7944 - mae: 0.5465\n",
            "Epoch 23/100\n",
            "24/24 [==============================] - 1s 41ms/step - loss: 4.2414 - mae: 0.5530\n",
            "Epoch 24/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 3.8571 - mae: 0.5592\n",
            "Epoch 25/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 3.5120 - mae: 0.5480\n",
            "Epoch 26/100\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 3.2042 - mae: 0.5446\n",
            "Epoch 27/100\n",
            "24/24 [==============================] - 1s 41ms/step - loss: 2.9253 - mae: 0.5465\n",
            "Epoch 28/100\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 2.6634 - mae: 0.5439\n",
            "Epoch 29/100\n",
            "24/24 [==============================] - 1s 37ms/step - loss: 2.4167 - mae: 0.5430\n",
            "Epoch 30/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 2.2101 - mae: 0.5550\n",
            "Epoch 31/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 2.0075 - mae: 0.5468\n",
            "Epoch 32/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.8351 - mae: 0.5523\n",
            "Epoch 33/100\n",
            "24/24 [==============================] - 1s 41ms/step - loss: 1.7018 - mae: 0.5602\n",
            "Epoch 34/100\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 1.5430 - mae: 0.5567\n",
            "Epoch 35/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.4062 - mae: 0.5367\n",
            "Epoch 36/100\n",
            "24/24 [==============================] - 1s 41ms/step - loss: 1.3361 - mae: 0.5612\n",
            "Epoch 37/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.2505 - mae: 0.5508\n",
            "Epoch 38/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1914 - mae: 0.5461\n",
            "Epoch 39/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1601 - mae: 0.5492\n",
            "Epoch 40/100\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 1.1554 - mae: 0.5530\n",
            "Epoch 41/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 1.1235 - mae: 0.5408\n",
            "Epoch 42/100\n",
            "24/24 [==============================] - 1s 59ms/step - loss: 1.1418 - mae: 0.5475\n",
            "Epoch 43/100\n",
            "24/24 [==============================] - 2s 65ms/step - loss: 1.1332 - mae: 0.5421\n",
            "Epoch 44/100\n",
            "24/24 [==============================] - 1s 44ms/step - loss: 1.1202 - mae: 0.5339\n",
            "Epoch 45/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1196 - mae: 0.5385\n",
            "Epoch 46/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1511 - mae: 0.5564\n",
            "Epoch 47/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1489 - mae: 0.5530\n",
            "Epoch 48/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1249 - mae: 0.5428\n",
            "Epoch 49/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1164 - mae: 0.5380\n",
            "Epoch 50/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1263 - mae: 0.5428\n",
            "Epoch 51/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1198 - mae: 0.5347\n",
            "Epoch 52/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1252 - mae: 0.5348\n",
            "Epoch 53/100\n",
            "24/24 [==============================] - 1s 41ms/step - loss: 1.1220 - mae: 0.5363\n",
            "Epoch 54/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1422 - mae: 0.5480\n",
            "Epoch 55/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1511 - mae: 0.5512\n",
            "Epoch 56/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1243 - mae: 0.5347\n",
            "Epoch 57/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1339 - mae: 0.5475\n",
            "Epoch 58/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 1.1209 - mae: 0.5369\n",
            "Epoch 59/100\n",
            "24/24 [==============================] - 1s 61ms/step - loss: 1.1276 - mae: 0.5473\n",
            "Epoch 60/100\n",
            "24/24 [==============================] - 2s 63ms/step - loss: 1.1438 - mae: 0.5555\n",
            "Epoch 61/100\n",
            "24/24 [==============================] - 1s 48ms/step - loss: 1.1362 - mae: 0.5481\n",
            "Epoch 62/100\n",
            "24/24 [==============================] - 1s 41ms/step - loss: 1.1193 - mae: 0.5342\n",
            "Epoch 63/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1495 - mae: 0.5466\n",
            "Epoch 64/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1305 - mae: 0.5471\n",
            "Epoch 65/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1206 - mae: 0.5370\n",
            "Epoch 66/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1293 - mae: 0.5427\n",
            "Epoch 67/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.1197 - mae: 0.5397\n",
            "Epoch 68/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1489 - mae: 0.5527\n",
            "Epoch 69/100\n",
            "24/24 [==============================] - 1s 37ms/step - loss: 1.1360 - mae: 0.5484\n",
            "Epoch 70/100\n",
            "24/24 [==============================] - 1s 35ms/step - loss: 1.1365 - mae: 0.5469\n",
            "Epoch 71/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1217 - mae: 0.5313\n",
            "Epoch 72/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1232 - mae: 0.5347\n",
            "Epoch 73/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1248 - mae: 0.5388\n",
            "Epoch 74/100\n",
            "24/24 [==============================] - 1s 32ms/step - loss: 1.1381 - mae: 0.5417\n",
            "Epoch 75/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.1247 - mae: 0.5376\n",
            "Epoch 76/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1411 - mae: 0.5503\n",
            "Epoch 77/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1418 - mae: 0.5484\n",
            "Epoch 78/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1229 - mae: 0.5323\n",
            "Epoch 79/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1103 - mae: 0.5294\n",
            "Epoch 80/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.1467 - mae: 0.5545\n",
            "Epoch 81/100\n",
            "24/24 [==============================] - 1s 37ms/step - loss: 1.1140 - mae: 0.5338\n",
            "Epoch 82/100\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 1.1244 - mae: 0.5416\n",
            "Epoch 83/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1447 - mae: 0.5466\n",
            "Epoch 84/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1424 - mae: 0.5528\n",
            "Epoch 85/100\n",
            "24/24 [==============================] - 1s 35ms/step - loss: 1.1233 - mae: 0.5421\n",
            "Epoch 86/100\n",
            "24/24 [==============================] - 1s 37ms/step - loss: 1.1334 - mae: 0.5475\n",
            "Epoch 87/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1357 - mae: 0.5465\n",
            "Epoch 88/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.1334 - mae: 0.5471\n",
            "Epoch 89/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1235 - mae: 0.5417\n",
            "Epoch 90/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1160 - mae: 0.5353\n",
            "Epoch 91/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1075 - mae: 0.5346\n",
            "Epoch 92/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.1337 - mae: 0.5430\n",
            "Epoch 93/100\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 1.1099 - mae: 0.5260\n",
            "Epoch 94/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1263 - mae: 0.5442\n",
            "Epoch 95/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.1200 - mae: 0.5375\n",
            "Epoch 96/100\n",
            "24/24 [==============================] - 1s 41ms/step - loss: 1.1233 - mae: 0.5427\n",
            "Epoch 97/100\n",
            "24/24 [==============================] - 1s 41ms/step - loss: 1.1339 - mae: 0.5488\n",
            "Epoch 98/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1168 - mae: 0.5358\n",
            "Epoch 99/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1284 - mae: 0.5447\n",
            "Epoch 100/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.1378 - mae: 0.5410\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.1121 - mae: 0.5174\n",
            "[CV 1/3; 1/1] END kr__act=sigmoid, kr__decay=1e-09, kr__dropout=0.1, kr__input_shape=17, kr__l1=0.01, kr__l2=0.003, kr__lr=0.01, kr__momentum=0.3, kr__nl1=0, kr__nl2=3, kr__nl3=2, kr__nn1=300, kr__nn2=800, kr__nn3=150;, score=-1.112 total time= 1.6min\n",
            "[CV 2/3; 1/1] START kr__act=sigmoid, kr__decay=1e-09, kr__dropout=0.1, kr__input_shape=17, kr__l1=0.01, kr__l2=0.003, kr__lr=0.01, kr__momentum=0.3, kr__nl1=0, kr__nl2=3, kr__nl3=2, kr__nn1=300, kr__nn2=800, kr__nn3=150\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 2s 38ms/step - loss: 446.6364 - mae: 0.8404\n",
            "Epoch 2/100\n",
            "24/24 [==============================] - 1s 37ms/step - loss: 396.8882 - mae: 0.5576\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 1s 32ms/step - loss: 351.3785 - mae: 0.5706\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 1s 34ms/step - loss: 308.7083 - mae: 0.5701\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 1s 41ms/step - loss: 268.8892 - mae: 0.5567\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 231.9332 - mae: 0.5482\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 1s 37ms/step - loss: 197.8469 - mae: 0.5496\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 1s 32ms/step - loss: 166.5973 - mae: 0.5613\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 138.1603 - mae: 0.5535\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 112.5252 - mae: 0.5290\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 1s 43ms/step - loss: 89.7880 - mae: 0.5389\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 2s 63ms/step - loss: 69.8825 - mae: 0.5559\n",
            "Epoch 13/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 52.7431 - mae: 0.5438\n",
            "Epoch 14/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 38.4430 - mae: 0.5498\n",
            "Epoch 15/100\n",
            "24/24 [==============================] - 1s 37ms/step - loss: 26.9305 - mae: 0.5381\n",
            "Epoch 16/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 18.2118 - mae: 0.5289\n",
            "Epoch 17/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 12.3249 - mae: 0.5508\n",
            "Epoch 18/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 9.1574 - mae: 0.5326\n",
            "Epoch 19/100\n",
            "24/24 [==============================] - 1s 37ms/step - loss: 7.6194 - mae: 0.5263\n",
            "Epoch 20/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 6.4236 - mae: 0.5350\n",
            "Epoch 21/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 5.4388 - mae: 0.5302\n",
            "Epoch 22/100\n",
            "24/24 [==============================] - 1s 36ms/step - loss: 4.6942 - mae: 0.5364\n",
            "Epoch 23/100\n",
            "24/24 [==============================] - 1s 32ms/step - loss: 4.1497 - mae: 0.5326\n",
            "Epoch 24/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 3.7988 - mae: 0.5417\n",
            "Epoch 25/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 3.4683 - mae: 0.5479\n",
            "Epoch 26/100\n",
            "24/24 [==============================] - 1s 37ms/step - loss: 3.1437 - mae: 0.5326\n",
            "Epoch 27/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 2.8682 - mae: 0.5347\n",
            "Epoch 28/100\n",
            "24/24 [==============================] - 1s 35ms/step - loss: 2.6285 - mae: 0.5420\n",
            "Epoch 29/100\n",
            "24/24 [==============================] - 1s 34ms/step - loss: 2.3694 - mae: 0.5287\n",
            "Epoch 30/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 2.1851 - mae: 0.5499\n",
            "Epoch 31/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.9767 - mae: 0.5426\n",
            "Epoch 32/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.7796 - mae: 0.5298\n",
            "Epoch 33/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.6484 - mae: 0.5401\n",
            "Epoch 34/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.4948 - mae: 0.5297\n",
            "Epoch 35/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.3744 - mae: 0.5257\n",
            "Epoch 36/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.2875 - mae: 0.5288\n",
            "Epoch 37/100\n",
            "24/24 [==============================] - 1s 41ms/step - loss: 1.2140 - mae: 0.5344\n",
            "Epoch 38/100\n",
            "24/24 [==============================] - 2s 84ms/step - loss: 1.1776 - mae: 0.5360\n",
            "Epoch 39/100\n",
            "24/24 [==============================] - 1s 60ms/step - loss: 1.1171 - mae: 0.5277\n",
            "Epoch 40/100\n",
            "24/24 [==============================] - 1s 37ms/step - loss: 1.1154 - mae: 0.5277\n",
            "Epoch 41/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.1235 - mae: 0.5321\n",
            "Epoch 42/100\n",
            "24/24 [==============================] - 1s 37ms/step - loss: 1.0933 - mae: 0.5151\n",
            "Epoch 43/100\n",
            "24/24 [==============================] - 1s 46ms/step - loss: 1.1148 - mae: 0.5298\n",
            "Epoch 44/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1207 - mae: 0.5362\n",
            "Epoch 45/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1190 - mae: 0.5332\n",
            "Epoch 46/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1132 - mae: 0.5250\n",
            "Epoch 47/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.1079 - mae: 0.5232\n",
            "Epoch 48/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.1118 - mae: 0.5267\n",
            "Epoch 49/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1158 - mae: 0.5299\n",
            "Epoch 50/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.1039 - mae: 0.5206\n",
            "Epoch 51/100\n",
            "24/24 [==============================] - 1s 37ms/step - loss: 1.1006 - mae: 0.5265\n",
            "Epoch 52/100\n",
            "24/24 [==============================] - 1s 37ms/step - loss: 1.0958 - mae: 0.5150\n",
            "Epoch 53/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.1191 - mae: 0.5322\n",
            "Epoch 54/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1198 - mae: 0.5354\n",
            "Epoch 55/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.0996 - mae: 0.5211\n",
            "Epoch 56/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.0939 - mae: 0.5209\n",
            "Epoch 57/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.1065 - mae: 0.5236\n",
            "Epoch 58/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.1057 - mae: 0.5224\n",
            "Epoch 59/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.1171 - mae: 0.5307\n",
            "Epoch 60/100\n",
            "24/24 [==============================] - 1s 37ms/step - loss: 1.1184 - mae: 0.5278\n",
            "Epoch 61/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.1048 - mae: 0.5260\n",
            "Epoch 62/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.1107 - mae: 0.5259\n",
            "Epoch 63/100\n",
            "24/24 [==============================] - 1s 34ms/step - loss: 1.1293 - mae: 0.5396\n",
            "Epoch 64/100\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 1.1225 - mae: 0.5341\n",
            "Epoch 65/100\n",
            "24/24 [==============================] - 1s 34ms/step - loss: 1.1067 - mae: 0.5249\n",
            "Epoch 66/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.1136 - mae: 0.5320\n",
            "Epoch 67/100\n",
            "24/24 [==============================] - 1s 37ms/step - loss: 1.1200 - mae: 0.5304\n",
            "Epoch 68/100\n",
            "24/24 [==============================] - 1s 37ms/step - loss: 1.1094 - mae: 0.5328\n",
            "Epoch 69/100\n",
            "24/24 [==============================] - 1s 37ms/step - loss: 1.0919 - mae: 0.5131\n",
            "Epoch 70/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.0987 - mae: 0.5140\n",
            "Epoch 71/100\n",
            "24/24 [==============================] - 1s 36ms/step - loss: 1.1122 - mae: 0.5235\n",
            "Epoch 72/100\n",
            "24/24 [==============================] - 1s 34ms/step - loss: 1.1136 - mae: 0.5311\n",
            "Epoch 73/100\n",
            "24/24 [==============================] - 1s 37ms/step - loss: 1.1006 - mae: 0.5193\n",
            "Epoch 74/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.0936 - mae: 0.5165\n",
            "Epoch 75/100\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 1.1184 - mae: 0.5339\n",
            "Epoch 76/100\n",
            "24/24 [==============================] - 1s 36ms/step - loss: 1.1039 - mae: 0.5181\n",
            "Epoch 77/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.1186 - mae: 0.5266\n",
            "Epoch 78/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1123 - mae: 0.5284\n",
            "Epoch 79/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.0916 - mae: 0.5166\n",
            "Epoch 80/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.0905 - mae: 0.5163\n",
            "Epoch 81/100\n",
            "24/24 [==============================] - 1s 37ms/step - loss: 1.1093 - mae: 0.5277\n",
            "Epoch 82/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.0986 - mae: 0.5167\n",
            "Epoch 83/100\n",
            "24/24 [==============================] - 1s 37ms/step - loss: 1.0994 - mae: 0.5223\n",
            "Epoch 84/100\n",
            "24/24 [==============================] - 1s 37ms/step - loss: 1.1139 - mae: 0.5337\n",
            "Epoch 85/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.1126 - mae: 0.5254\n",
            "Epoch 86/100\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 1.0978 - mae: 0.5223\n",
            "Epoch 87/100\n",
            "24/24 [==============================] - 1s 35ms/step - loss: 1.0914 - mae: 0.5151\n",
            "Epoch 88/100\n",
            "24/24 [==============================] - 1s 36ms/step - loss: 1.1202 - mae: 0.5352\n",
            "Epoch 89/100\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 1.1080 - mae: 0.5289\n",
            "Epoch 90/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.0846 - mae: 0.5124\n",
            "Epoch 91/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.1015 - mae: 0.5189\n",
            "Epoch 92/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.1101 - mae: 0.5272\n",
            "Epoch 93/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.1076 - mae: 0.5269\n",
            "Epoch 94/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1056 - mae: 0.5249\n",
            "Epoch 95/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.0967 - mae: 0.5150\n",
            "Epoch 96/100\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 1.1163 - mae: 0.5377\n",
            "Epoch 97/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1009 - mae: 0.5204\n",
            "Epoch 98/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1165 - mae: 0.5350\n",
            "Epoch 99/100\n",
            "24/24 [==============================] - 1s 47ms/step - loss: 1.1122 - mae: 0.5275\n",
            "Epoch 100/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 1.1032 - mae: 0.5175\n",
            "12/12 [==============================] - 1s 18ms/step - loss: 1.1186 - mae: 0.5356\n",
            "[CV 2/3; 1/1] END kr__act=sigmoid, kr__decay=1e-09, kr__dropout=0.1, kr__input_shape=17, kr__l1=0.01, kr__l2=0.003, kr__lr=0.01, kr__momentum=0.3, kr__nl1=0, kr__nl2=3, kr__nl3=2, kr__nn1=300, kr__nn2=800, kr__nn3=150;, score=-1.119 total time= 1.6min\n",
            "[CV 3/3; 1/1] START kr__act=sigmoid, kr__decay=1e-09, kr__dropout=0.1, kr__input_shape=17, kr__l1=0.01, kr__l2=0.003, kr__lr=0.01, kr__momentum=0.3, kr__nl1=0, kr__nl2=3, kr__nl3=2, kr__nn1=300, kr__nn2=800, kr__nn3=150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "24/24 [==============================] - 3s 41ms/step - loss: 446.9306 - mae: 0.9057\n",
            "Epoch 2/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 396.6334 - mae: 0.5582\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 351.1497 - mae: 0.5685\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 308.5439 - mae: 0.5726\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 268.7505 - mae: 0.5560\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 231.8841 - mae: 0.5787\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 197.8209 - mae: 0.5608\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 166.6170 - mae: 0.5665\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 1s 35ms/step - loss: 138.2061 - mae: 0.5535\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 112.6727 - mae: 0.5703\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 89.9157 - mae: 0.5636\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 69.9784 - mae: 0.5711\n",
            "Epoch 13/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 52.8401 - mae: 0.5486\n",
            "Epoch 14/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 38.5542 - mae: 0.5523\n",
            "Epoch 15/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 27.0540 - mae: 0.5638\n",
            "Epoch 16/100\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 18.3381 - mae: 0.5498\n",
            "Epoch 17/100\n",
            "24/24 [==============================] - 1s 60ms/step - loss: 12.4319 - mae: 0.5609\n",
            "Epoch 18/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 9.2661 - mae: 0.5588\n",
            "Epoch 19/100\n",
            "24/24 [==============================] - 1s 63ms/step - loss: 7.7426 - mae: 0.5675\n",
            "Epoch 20/100\n",
            "24/24 [==============================] - 1s 36ms/step - loss: 6.5058 - mae: 0.5465\n",
            "Epoch 21/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 5.5317 - mae: 0.5750\n",
            "Epoch 22/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 4.7695 - mae: 0.5667\n",
            "Epoch 23/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 4.2167 - mae: 0.5629\n",
            "Epoch 24/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 3.8311 - mae: 0.5588\n",
            "Epoch 25/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 3.4774 - mae: 0.5475\n",
            "Epoch 26/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 3.1770 - mae: 0.5453\n",
            "Epoch 27/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 2.9036 - mae: 0.5520\n",
            "Epoch 28/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 2.6341 - mae: 0.5397\n",
            "Epoch 29/100\n",
            "24/24 [==============================] - 1s 36ms/step - loss: 2.3999 - mae: 0.5448\n",
            "Epoch 30/100\n",
            "24/24 [==============================] - 1s 35ms/step - loss: 2.1756 - mae: 0.5474\n",
            "Epoch 31/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.9848 - mae: 0.5460\n",
            "Epoch 32/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.8125 - mae: 0.5473\n",
            "Epoch 33/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.6734 - mae: 0.5581\n",
            "Epoch 34/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.5283 - mae: 0.5558\n",
            "Epoch 35/100\n",
            "24/24 [==============================] - 1s 32ms/step - loss: 1.4018 - mae: 0.5443\n",
            "Epoch 36/100\n",
            "24/24 [==============================] - 1s 37ms/step - loss: 1.3094 - mae: 0.5478\n",
            "Epoch 37/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.2423 - mae: 0.5495\n",
            "Epoch 38/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1967 - mae: 0.5483\n",
            "Epoch 39/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1606 - mae: 0.5547\n",
            "Epoch 40/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1361 - mae: 0.5480\n",
            "Epoch 41/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1331 - mae: 0.5441\n",
            "Epoch 42/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1292 - mae: 0.5505\n",
            "Epoch 43/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1409 - mae: 0.5552\n",
            "Epoch 44/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1556 - mae: 0.5600\n",
            "Epoch 45/100\n",
            "24/24 [==============================] - 1s 32ms/step - loss: 1.1398 - mae: 0.5441\n",
            "Epoch 46/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1323 - mae: 0.5423\n",
            "Epoch 47/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1404 - mae: 0.5518\n",
            "Epoch 48/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1268 - mae: 0.5449\n",
            "Epoch 49/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1286 - mae: 0.5401\n",
            "Epoch 50/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1454 - mae: 0.5550\n",
            "Epoch 51/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1402 - mae: 0.5479\n",
            "Epoch 52/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1550 - mae: 0.5613\n",
            "Epoch 53/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1318 - mae: 0.5418\n",
            "Epoch 54/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1273 - mae: 0.5443\n",
            "Epoch 55/100\n",
            "24/24 [==============================] - 1s 43ms/step - loss: 1.1387 - mae: 0.5497\n",
            "Epoch 56/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1375 - mae: 0.5452\n",
            "Epoch 57/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1253 - mae: 0.5400\n",
            "Epoch 58/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.1147 - mae: 0.5334\n",
            "Epoch 59/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.1233 - mae: 0.5397\n",
            "Epoch 60/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1544 - mae: 0.5585\n",
            "Epoch 61/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1268 - mae: 0.5388\n",
            "Epoch 62/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1417 - mae: 0.5511\n",
            "Epoch 63/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1343 - mae: 0.5494\n",
            "Epoch 64/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1431 - mae: 0.5556\n",
            "Epoch 65/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1318 - mae: 0.5441\n",
            "Epoch 66/100\n",
            "24/24 [==============================] - 1s 41ms/step - loss: 1.1469 - mae: 0.5579\n",
            "Epoch 67/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1388 - mae: 0.5509\n",
            "Epoch 68/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1358 - mae: 0.5525\n",
            "Epoch 69/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.1314 - mae: 0.5465\n",
            "Epoch 70/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1408 - mae: 0.5573\n",
            "Epoch 71/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1266 - mae: 0.5432\n",
            "Epoch 72/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1248 - mae: 0.5421\n",
            "Epoch 73/100\n",
            "24/24 [==============================] - 1s 32ms/step - loss: 1.1137 - mae: 0.5389\n",
            "Epoch 74/100\n",
            "24/24 [==============================] - 1s 37ms/step - loss: 1.1291 - mae: 0.5470\n",
            "Epoch 75/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1278 - mae: 0.5432\n",
            "Epoch 76/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1301 - mae: 0.5462\n",
            "Epoch 77/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1207 - mae: 0.5330\n",
            "Epoch 78/100\n",
            "24/24 [==============================] - 1s 41ms/step - loss: 1.1272 - mae: 0.5498\n",
            "Epoch 79/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1272 - mae: 0.5474\n",
            "Epoch 80/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1348 - mae: 0.5431\n",
            "Epoch 81/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1357 - mae: 0.5428\n",
            "Epoch 82/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1343 - mae: 0.5471\n",
            "Epoch 83/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1341 - mae: 0.5424\n",
            "Epoch 84/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1231 - mae: 0.5429\n",
            "Epoch 85/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.1460 - mae: 0.5507\n",
            "Epoch 86/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.1371 - mae: 0.5469\n",
            "Epoch 87/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1510 - mae: 0.5563\n",
            "Epoch 88/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1150 - mae: 0.5379\n",
            "Epoch 89/100\n",
            "24/24 [==============================] - 1s 36ms/step - loss: 1.1367 - mae: 0.5503\n",
            "Epoch 90/100\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 1.1363 - mae: 0.5475\n",
            "Epoch 91/100\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 1.1417 - mae: 0.5501\n",
            "Epoch 92/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1410 - mae: 0.5435\n",
            "Epoch 93/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 1.1215 - mae: 0.5328\n",
            "Epoch 94/100\n",
            "24/24 [==============================] - 1s 41ms/step - loss: 1.1175 - mae: 0.5321\n",
            "Epoch 95/100\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 1.1308 - mae: 0.5473\n",
            "Epoch 96/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 1.1338 - mae: 0.5481\n",
            "Epoch 97/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1269 - mae: 0.5429\n",
            "Epoch 98/100\n",
            "24/24 [==============================] - 1s 37ms/step - loss: 1.1309 - mae: 0.5466\n",
            "Epoch 99/100\n",
            "24/24 [==============================] - 1s 35ms/step - loss: 1.1349 - mae: 0.5469\n",
            "Epoch 100/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.1300 - mae: 0.5465\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.1075 - mae: 0.5347\n",
            "[CV 3/3; 1/1] END kr__act=sigmoid, kr__decay=1e-09, kr__dropout=0.1, kr__input_shape=17, kr__l1=0.01, kr__l2=0.003, kr__lr=0.01, kr__momentum=0.3, kr__nl1=0, kr__nl2=3, kr__nl3=2, kr__nn1=300, kr__nn2=800, kr__nn3=150;, score=-1.108 total time= 1.6min\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36/36 [==============================] - 2s 36ms/step - loss: 434.4590 - mae: 0.7932\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 1s 37ms/step - loss: 362.6921 - mae: 0.5902\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 1s 37ms/step - loss: 298.6281 - mae: 0.5663\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 1s 36ms/step - loss: 241.0412 - mae: 0.5578\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 1s 30ms/step - loss: 189.9453 - mae: 0.5686\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 1s 37ms/step - loss: 145.2738 - mae: 0.5837\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 1s 36ms/step - loss: 106.9263 - mae: 0.5765\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 1s 36ms/step - loss: 74.9182 - mae: 0.5700\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 1s 37ms/step - loss: 49.2453 - mae: 0.5670\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 1s 37ms/step - loss: 29.8621 - mae: 0.5574\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 1s 36ms/step - loss: 16.7725 - mae: 0.5612\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 1s 36ms/step - loss: 9.9404 - mae: 0.5630\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 7.4155 - mae: 0.5599\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 5.7456 - mae: 0.5555\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 1s 31ms/step - loss: 4.5822 - mae: 0.5388\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 1s 29ms/step - loss: 3.9118 - mae: 0.5532\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 1s 29ms/step - loss: 3.4136 - mae: 0.5526\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 1s 30ms/step - loss: 2.9537 - mae: 0.5377\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 1s 34ms/step - loss: 2.5843 - mae: 0.5424\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 1s 33ms/step - loss: 2.2257 - mae: 0.5412\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 1s 36ms/step - loss: 1.9339 - mae: 0.5374\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 1s 35ms/step - loss: 1.6807 - mae: 0.5343\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 1s 37ms/step - loss: 1.4833 - mae: 0.5356\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 1s 37ms/step - loss: 1.3357 - mae: 0.5389\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 1s 36ms/step - loss: 1.2205 - mae: 0.5390\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 1s 35ms/step - loss: 1.1565 - mae: 0.5380\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 1s 36ms/step - loss: 1.1347 - mae: 0.5405\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 1s 37ms/step - loss: 1.1081 - mae: 0.5318\n",
            "Epoch 29/100\n",
            "23/36 [==================>...........] - ETA: 0s - loss: 1.1262 - mae: 0.5369"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-165-65e807ee1ed0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "id": "_lVqbqxuK03z",
        "outputId": "2343fd22-f347-47ba-da4e-3d278f9f7f91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_lVqbqxuK03z",
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: -33.459644 using {'kr__nn3': 300, 'kr__nn2': 100, 'kr__nn1': 2100, 'kr__nl3': 1, 'kr__nl2': 1, 'kr__nl1': 0, 'kr__momentum': 0.3, 'kr__lr': 0.0001, 'kr__l2': 0.1, 'kr__l1': 0.01, 'kr__input_shape': 17, 'kr__dropout': 0, 'kr__decay': 1e-09, 'kr__act': 'relu'}\n",
            "-33.459644 (0.174639) with: {'kr__nn3': 300, 'kr__nn2': 100, 'kr__nn1': 2100, 'kr__nl3': 1, 'kr__nl2': 1, 'kr__nl1': 0, 'kr__momentum': 0.3, 'kr__lr': 0.0001, 'kr__l2': 0.1, 'kr__l1': 0.01, 'kr__input_shape': 17, 'kr__dropout': 0, 'kr__decay': 1e-09, 'kr__act': 'relu'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#kr__act=relu, kr__decay=1e-06, kr__dropout=0, kr__input_shape=17, kr__l1=0, kr__l2=0, kr__lr=0.001, kr__momentum=0.5, kr__nl1=3, kr__nl2=3, kr__nl3=1, kr__nn1=2100, kr__nn2=100, kr__nn3=300"
      ],
      "metadata": {
        "id": "kAFtaTppmN4t"
      },
      "id": "kAFtaTppmN4t",
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_result.best_score_"
      ],
      "metadata": {
        "id": "6-ZtlEWnLD5j",
        "outputId": "8dfb10b6-b32e-47bb-ba54-4d3632ea4f6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "6-ZtlEWnLD5j",
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-33.45964431762695"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = grid_result.best_estimator_"
      ],
      "metadata": {
        "id": "ard6yMptLHr9"
      },
      "id": "ard6yMptLHr9",
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "test = pd.read_csv('data/laptop_test.csv')\n",
        "test = test.dropna()\n",
        "\n",
        "df_nn = test.copy()\n",
        "\n",
        "neural_network_pred = best_model.predict(df_nn[features])\n",
        "neural_network_r2 = r2_score(np.exp(neural_network_pred), np.exp(df_nn[target]))\n",
        "print(\"Neural Network\\nR2: {:.4f} %\".format(neural_network_r2*100))"
      ],
      "metadata": {
        "id": "BGAbqR1pLuQD",
        "outputId": "9fb74b38-5938-488a-cee6-a2355e83bd81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "BGAbqR1pLuQD",
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/5 [=====>........................] - ETA: 0s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 5ms/step\n",
            "Neural Network\n",
            "R2: 25.7491 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.exp(neural_network_pred)"
      ],
      "metadata": {
        "id": "MuAYD6FnfqoP",
        "outputId": "aa838aca-4534-417e-987e-40f8d267dace",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "MuAYD6FnfqoP",
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525,\n",
              "       1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525,\n",
              "       1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525,\n",
              "       1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525,\n",
              "       1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525,\n",
              "       1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525,\n",
              "       1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525,\n",
              "       1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525,\n",
              "       1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525,\n",
              "       1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525,\n",
              "       1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525,\n",
              "       1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525,\n",
              "       1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525,\n",
              "       1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525,\n",
              "       1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525,\n",
              "       1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525,\n",
              "       1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525,\n",
              "       1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525,\n",
              "       1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525,\n",
              "       1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525,\n",
              "       1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525,\n",
              "       1634.4525, 1634.4525, 1634.4525, 1634.4525, 1634.4525],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.exp(df_nn[target])"
      ],
      "metadata": {
        "id": "CqCOt_S0fsPI",
        "outputId": "154493d0-b743-431c-90cc-9fed038b8389",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "CqCOt_S0fsPI",
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1672.0\n",
              "1      1149.0\n",
              "2       499.0\n",
              "3       899.0\n",
              "4      1244.0\n",
              "        ...  \n",
              "126    1099.0\n",
              "127     649.0\n",
              "128    1379.0\n",
              "129     699.0\n",
              "130    1271.0\n",
              "Name: log_price, Length: 131, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the model"
      ],
      "metadata": {
        "id": "LlZXZty-ZkTt"
      },
      "id": "LlZXZty-ZkTt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's save the model. I will later compare the performance of different models on the testing dataset"
      ],
      "metadata": {
        "id": "mc_dhEb7i9wb"
      },
      "id": "mc_dhEb7i9wb"
    },
    {
      "cell_type": "code",
      "source": [
        "model_reloaded.save(\"models/neural_network.h5\")"
      ],
      "metadata": {
        "id": "CSheVeILdaIK",
        "outputId": "91442698-8cbe-4174-d47b-dcdd3367cd0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "id": "CSheVeILdaIK",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-d5172241f286>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_reloaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models/neural_network.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model_reloaded' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model"
      ],
      "metadata": {
        "id": "5pBPt3Xm7-mX",
        "outputId": "bda29949-5753-41fa-d400-a084338652f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5pBPt3Xm7-mX",
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('sc', StandardScaler()),\n",
              "                ('kr',\n",
              "                 <keras.wrappers.scikit_learn.KerasRegressor object at 0x7fbd152c8a60>)])"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('nn.pkl', 'wb') as file:\n",
        "    pickle.dump(best_model, file)"
      ],
      "metadata": {
        "id": "yQ2JOlajw4gR"
      },
      "id": "yQ2JOlajw4gR",
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.save('saved_model.h5')"
      ],
      "metadata": {
        "id": "rFfCX4Vd3fRM",
        "outputId": "2b9b28e4-9892-4782-f2a3-1e167efe3d15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "id": "rFfCX4Vd3fRM",
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-164-c828e43e4641>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saved_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'save'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pik__jsb9X3U"
      },
      "id": "pik__jsb9X3U",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}